{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "Feed-Forward Neural Networks vs Convolution Neural Networks\n",
    "\n",
    "## Description :\n",
    "The aim of this exercise is to train a feed-forward neural network and a convolutional neural network and compare the number of parameters between them on the following image classification task: \n",
    "\n",
    "<img src=\"../fig/fig1.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- Since we have only one 'Pavlos' and one 'Not Pavlos' image, we will need to augment our dataset. We use an image generator to create 'translated' versions of our two images. The training is performed on these translated images given in the data folder.\n",
    "- **Feed-Forward Neural Network:**\n",
    "    - Build a simple Feed-Forward Neural Network and compile the model with binary cross entropy as the loss. \n",
    "    - Fit the model on the training data and save the history.\n",
    "    - Predict on the entire data. \n",
    "    - Visualize the loss and accuracy on train and validation data with respect to the epochs.\n",
    "- **Convolutional Neural Network:**\n",
    "    - Build a Convolution Neural Networks and compile the model with binary cross-entropy as the loss.  \n",
    "    - Fit the model on the training data and save the history.\n",
    "    - Predict on the entire data. \n",
    "    - Visualize the loss and accuracy on train and validation data with respect to the epochs.\n",
    "- Compare the accuracy and the number of parameters of both the models.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "<a href=\"https://keras.io/guides/sequential_model/\" target=\"_blank\">keras.Sequential()</a>\n",
    "Creates a sequential model. A `Sequential` model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "<a href=\"https://keras.io/api/models/model_training_apis/#compile-method\" target=\"_blank\">keras.compile()</a>\n",
    "Configures the model for training.\n",
    "\n",
    "<a href=\"https://keras.io/api/models/model_training_apis/#fit-method\" target=\"_blank\">keras.fit()</a>\n",
    "Trains the model for a fixed number of epochs.\n",
    "\n",
    "<a href=\"https://keras.io/guides/training_with_built_in_methods/\" target=\"_blank\">history.history[]</a>\n",
    "The returned \"history\" object from `model.fit()` holds a dictionary of the loss values and metric values during training.\n",
    "\n",
    "<a href=\"https://keras.io/api/models/model_training_apis/#evaluate-method\" target=\"_blank\">keras.evaluate()</a>\n",
    "Returns the loss value & metrics values for the model in test mode.\n",
    "\n",
    "<a href=\"https://keras.io/api/preprocessing/image/#imagedatagenerator-class\" target=\"_blank\">tf.keras.preprocessing.image.ImageDataGenerator()</a>\n",
    "Generate batches of tensor image data with real-time data augmentation. This function is used in our helper code. \n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Flatten\" target=\"_blank\">tf.keras.layers.Flatten()</a>\n",
    "Flattens the input. Does not affect the batch size.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\" target=\"_blank\">tf.keras.layers.Conv2D()</a>\n",
    "2D convolution layer (e.g. spatial convolution over images).\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\" target=\"_blank\">tf.keras.layers.Dense()</a>\n",
    "A regular densely-connected NN layer.\n",
    "\n",
    "NOTE - The accuracy testing is done on the original network. Ensure to reset to the original parameters after answering the pause and think questions to pass the tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Input\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from helper import plot_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise an image generator object\n",
    "generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Initialising number of data images\n",
    "num_data = len(os.listdir('data/pavlos') + os.listdir('data/not_pavlos'))\n",
    "\n",
    "# Read the image data from the directory using the generator object\n",
    "img_generator = generator.flow_from_directory(directory=\"data/\", color_mode='rgb', seed=1,\n",
    "                                    batch_size=16, target_size=(150, 150), class_mode='binary')\n",
    "\n",
    "# Print the target size i.e. the total dataset size\n",
    "TARGET_SIZE = img_generator.target_size\n",
    "print(f'Generator produces images of size {TARGET_SIZE} (with 3 color channels)')\n",
    "\n",
    "# Print the batch size\n",
    "BATCH_SIZE = img_generator.batch_size\n",
    "print(f'Images are generated in batches of size {BATCH_SIZE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a sample of the generated images \n",
    "sample_batch = img_generator.next()[0]\n",
    "fig, ax = plt.subplots(4,4)\n",
    "ax = ax.ravel()\n",
    "for i, img in enumerate(sample_batch):\n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].imshow(img)\n",
    "plt.suptitle('Sample Batch of Generated Images', y=1.05)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Neural Network\n",
    "\n",
    "Our first network will be a feed-forward neural network. The only layers with learned parameters we will be using are dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fixing the random seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Creating a feed-forward Neural Network\n",
    "FFNN = Sequential()\n",
    "\n",
    "# Specify a layer that takes the input with input shape\n",
    "# the same as the size of the image defined during image generation\n",
    "# Remember to take into account that the image has 3 channels\n",
    "FFNN.add(___)\n",
    "\n",
    "# Add a flatten layer to enable FFNN to process images\n",
    "FFNN.add(___)\n",
    "\n",
    "# Specify a list of the number of nodes for each dense layer\n",
    "ffnn_filters = [6,4,2]\n",
    "\n",
    "# Add dense layers for the number of nodes in ffnn_filters with ReLU activation\n",
    "for n_nodes in ffnn_filters:\n",
    "    FFNN.add(___)\n",
    "\n",
    "# Add the final dense layer with 1 output node to differentiate \n",
    "# between the two classes and sigmoid activation\n",
    "FFNN.add(___))\n",
    "\n",
    "# Compile the model with accuracy as the metric and adam optimizer\n",
    "FFNN.compile(___)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the model and observe the total number of parameters\n",
    "FFNN.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "FFNN_history = FFNN.fit(\n",
    "        img_generator,\n",
    "        steps_per_epoch=num_data// BATCH_SIZE,\n",
    "        epochs=10, shuffle=False, workers=0,\n",
    "        validation_data=img_generator,\n",
    "        validation_steps=num_data*0.25// BATCH_SIZE)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ Enter the number of parameters in the given FFNN architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Enter the answer by typing in a number in the space provided\n",
    "answer1 = '___'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the plot history function from the helper file to plot the data\n",
    "plot_history(FFNN_history, 'Feed-Forward Neural Network')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_ffnn_acc) ###\n",
    "\n",
    "# Evaluate your model\n",
    "FFNN_loss, FFNN_acc = FFNN.evaluate(img_generator, steps=2)\n",
    "print(f'FFNN Accuracy: {FFNN_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ Alter the network architecture by increasing the number of nodes and/or layers. Enter the number of parameters of the network that gives a validation accuracy of above 80%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Enter the answer by typing in a number in the space provided\n",
    "answer2 = '___'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_cnn_count_param) ###\n",
    "\n",
    "# Fixing the random seed\n",
    "seed(1)\n",
    "tf.random.set_seed(1)\n",
    "\n",
    "# Creating a CNN\n",
    "CNN = Sequential()\n",
    "\n",
    "# Add a layer to take the input with shape (150,150,3)\n",
    "CNN.add(___)\n",
    "\n",
    "# Specify a list of the number of filters for each convolutional layer\n",
    "cnn_filters = [8,8,8,8,8]\n",
    "\n",
    "# Add convolutional layers with number of filters in cnn_filters\n",
    "# with kernel size as 3, stride of 2 and relu activation\n",
    "for n_filters in cnn_filters:\n",
    "    CNN.add(___)\n",
    "\n",
    "# Add the flatten layer between the CNN and dense layer\n",
    "CNN.add(___)\n",
    "\n",
    "# Add a dense layer with 64 nodes and relu activation\n",
    "CNN.add(___)\n",
    " \n",
    "# Specify the output layer with sigmoid activation and one node\n",
    "CNN.add(___)\n",
    " \n",
    "# Compile the model with accuracy as the metric and adam optimizer\n",
    "CNN.compile(___)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a summary of the model and observe the total number of parameters\n",
    "CNN.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ Enter the number of parameters in the given CNN architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow3) ###\n",
    "\n",
    "# Enter the answer by typing in a number in the space provided\n",
    "answer3 = '___'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the image generator\n",
    "CNN_history = CNN.fit(\n",
    "        img_generator,\n",
    "        steps_per_epoch=num_data // BATCH_SIZE,\n",
    "        epochs=10, shuffle=False, workers=0,\n",
    "        validation_data=img_generator,\n",
    "        validation_steps=num_data*0.25// BATCH_SIZE)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the history of the model\n",
    "plot_history(CNN_history, 'Convolutional Neural Network')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_cnn_acc) ###\n",
    "\n",
    "# Evaluate the model on the entire data\n",
    "CNN_loss, CNN_acc = CNN.evaluate(img_generator, steps=2)\n",
    "print(f'CNN Test Accuracy: {CNN_acc}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ Remove the last convolution layer in the Convolution Neural Network defined above. How does this affect the number of parameters?\n",
    "\n",
    "#### A. The number of parameters decrease.\n",
    "#### B. The number of parameters increase.\n",
    "#### C. The number of parameters remains the same. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow4) ###\n",
    "\n",
    "# Enter the answer by typing in a number in the space provided\n",
    "answer4 = '___'\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
