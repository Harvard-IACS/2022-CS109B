{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Advanced Section: Gaussian Mixture Models\n",
    "## CS 109B\n",
    "### Spring, 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"fig/logos.jpg\" style=\"height:150px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "### Import basic libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation for Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Model for Birth Weights\n",
    "Recall our model for birth weigths, $Y_1,\\ldots, Y_N$. We *posited* that the birth weights are iid normally distributed with known $\\sigma^2$, $Y_n \\sim \\mathcal{N}(\\mu, 1)$.\n",
    "\n",
    "Compare the maximum likelihood model and the Bayesian model for bith weight. Which model would you use to make clinical decisions? What's hard about this comparison?\n",
    "\n",
    "<img src=\"fig/compare.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Similarity Measure for Distributions: Kullback–Leibler Divergence\n",
    "\n",
    "Visually comparing models to the ***empirical distribution*** of the data is impractical. Fortunately, there are a large number of quantitative measures for comparing two distributions, these are called ***divergence measures***. For example, the ***Kullback–Leibler (KL) Divergence*** is defined for two distributions $p(\\theta)$ and $q(\\theta)$ supported on $\\Theta$ as:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}}[q \\,\\|\\, p] = \\int_{\\Theta} \\log\\left[\\frac{q(\\theta)}{p(\\theta)} \\right] q(\\theta)d\\theta\n",
    "$$\n",
    "\n",
    "The KL-divergence $D_{\\text{KL}}[q \\,\\|\\, p]$ is bounded below by 0, which happens if and only if $q=p$.\n",
    "The KL-divergence has information theoretic interpretations that we will explore later in the course.\n",
    "\n",
    "**Note:** The KL-divergence is defined in terms of the pdf's of $p$ and $q$. If $p$ is a distribution from which we only have samples and not the pdf (like the empirical distribution), we can nontheless estimate $D_{\\text{KL}}[q \\,\\|\\, p]$. Techniques that estimate the KL-divergence from samples are called ***non-parametric***. We will use them later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Why is the KL bounded below by 0?\n",
    "\n",
    "First let's see why the answer isn't obvious. Recall that the ***KL divergence is the expected log ratio between two distribution***:\n",
    "\n",
    "$$\n",
    "D_{\\text{KL}} [q\\| p] = \\mathbb{E}_{q}\\left[ \\log \\frac{q}{p}\\right]\n",
    "$$\n",
    "\n",
    "Now, we know that when $q$ is less than $p$ (i.e. $q/p < 1$) then the log can be an arbitrarily negative number. So it's not immediately obvious that the expected value of this fraction should always be non-negative!\n",
    "\n",
    "**An intuitive explanation:**\n",
    "\n",
    "Let the blue curve be q and the red be p. We have $q < p$ from $(-\\infty, 55)$, on this part of the domain $\\log(q/p)$ is negative. On $[55, \\infty)$, $\\log(q/p)$ is nonnegative.\n",
    "\n",
    "However, since we are sampling from $q$, and $q$'s mass is largely over $[55, \\infty)$, the log fraction $\\log(q/p$) will tend to be nonnegative.\n",
    "\n",
    "<img src=\"fig/kl.png\" style=\"height:300px;\">\n",
    "\n",
    "**A formal argument:**\n",
    "\n",
    "There are many proofs of the non-negativity of the KL. Ranging from the very complex to the very simple. Here is one that just involves a bit of algebra:\n",
    "\n",
    "We want to show that $D_{\\text{KL}}[q\\|p] \\geq 0$. Instead we'll show, equivalently, that $-D_{\\text{KL}}[q\\|p] \\leq 0$ (we're choosing show the statement about the negative KL, just so we can flip the fraction on the inside of the log and cancel terms):\n",
    "\n",
    "<img src=\"fig/derivation.png\" style=\"height:300px;\">\n",
    "\n",
    "<img src=\"fig/log.png\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Class Membership as a Latent Variable\n",
    "\n",
    "We observe that there are three ***clusters*** in the data. We posit that there are three ***classes*** of infants in the study: infants with low birth weights, infants with normal birth weights and those with high birth weights. The numbers of infants in the classes are not equal.\n",
    "\n",
    "For each observation $Y_n$, we model its class membership $Z_n$ as a categorical variable, \n",
    "\n",
    "$$Z_n\\sim Cat(\\pi),$$\n",
    "\n",
    "where $\\pi_i$ in $\\pi = [\\pi_1, \\pi_2, \\pi_3]$ is the class proportion. Note that we don't have the class membership $Z_n$ in the data! So $Z_n$ is called a ***latent variable***.\n",
    "\n",
    "Depending on the class, the $n$-th birth weight $Y_n$ will have a different normal distribution,\n",
    "\n",
    "$$\n",
    "Y_n | Z_n \\sim \\mathcal{N}\\left(\\mu_{Z_n}, \\sigma^2_{Z_n}\\right)\n",
    "$$\n",
    "\n",
    "where $\\mu_{Z_n}$ is one of the three class means $[\\mu_1, \\mu_2, \\mu_3]$ and $\\sigma^2_{Z_n}$ is one of the three class variances $[\\sigma^2_1, \\sigma^2_2, \\sigma^2_3]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Common Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Latent Variable Models\n",
    "\n",
    "Models that include an observed variable $Y$ and at least one unobserved variable $Z$ are called ***latent variable models***. In general, our model can allow $Y$ and $Z$ to interact in many different ways. Today, we will study models with one type of interaction:\n",
    "\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Gaussian Mixture Models (GMMs)\n",
    "\n",
    "In a ***Gaussian Mixture Model (GMM)***, we posit that the observed data $Y$ is generated by a mixture, $\\pi=[\\pi_1, \\ldots, \\pi_K]$, of $K$ number of Gaussians with means $\\mu = [\\mu_1, \\ldots, \\mu_K]$ and covariances $\\Sigma = [\\Sigma_1, \\ldots, \\Sigma_K]$. For each observation $Y_n$ the class of the observation $Z_n$ is a latent variable that indicates which of the $K$ Gaussian is responsible for generating $Y_n$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n | Z_n&\\sim \\mathcal{N}(\\mu_{Z_n}, \\Sigma_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "GMMs are examples of ***model based clustering*** - breaking up a data set into natural clusters based on a statistical model fitted to the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Item-Response Models\n",
    "\n",
    "In ***item-response models***, we measure an real-valued unobserved trait $Z$ of a subject by performing a series of experiments with binary observable outcomes, $Y$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim \\mathcal{N}(\\mu, \\sigma^2),\\\\\n",
    "\\theta_n &= g(Z_n)\\\\\n",
    "Y_n|Z_n &\\sim Ber(\\theta_n),\n",
    "\\end{aligned}\n",
    "\n",
    "where $n=1, \\ldots, N$ and $g$ is some fixed function of $Z_n$.\n",
    "\n",
    "#### Applications\n",
    "Item response models are used to model the way \"underlying intelligence\" $Z$ relates to scores $Y$ on IQ tests. \n",
    "\n",
    "Item response models can also be used to model the way \"suicidality\" $Z$ relates to answers on mental health surveys. Building a good model may help to infer when a patient is at psychiatric risk based on in-take surveys at points of care through out the health-care system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Factor Analysis Models\n",
    "\n",
    "In ***factor analysis models***, we posit that the observed data $Y$ with many measurements is generated by a small set of unobserved factors $Z$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim \\mathcal{N}(0, I),\\\\\n",
    "Y_n|Z_n &\\sim \\mathcal{N}(\\mu + \\Lambda Z_n, \\Phi),\n",
    "\\end{aligned}\n",
    "\n",
    "where $n=1, \\ldots, N$, $Z_n\\in \\mathbb{R}^{D'}$ and $Y_n\\in \\mathbb{R}^{D}$. We typically assume that $D'$ is much smaller than $D$.\n",
    "\n",
    "#### Applications\n",
    "Factor analysis models are useful for biomedical data, where we typically measure a large number of characteristics of a patient (e.g. blood pressure, heart rate, etc), but these characteristics are all generated by a small list of health factors (e.g. diabetes, cancer, hypertension etc). Building a good model means we may be able to infer the list of health factors of a patient from their observed measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Expectation Maximization: Estimating the MLE for Latent Variable Models\n",
    "\n",
    "Given a latent variable model $p(Y, Z| \\phi, \\theta) = p(Y | Z, \\phi) p(Z|\\theta)$, we are interested computing the MLE of parameters $\\phi$ and $\\theta$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\theta_{\\text{MLE}}, \\phi_{\\text{MLE}} &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\ell(\\theta, \\phi)\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\log \\prod_{n=1}^N \\int_{\\Omega_Z}  p(y_n, z_n | \\theta, \\phi) dz\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\log \\prod_{n=1}^N \\int_{\\Omega_Z}  p(y_n| z_n, \\phi)p(z_n| \\theta) dz\n",
    "\\end{aligned}\n",
    "where $\\Omega_Z$ is the domain of $Z$.\n",
    "Why is this an hard optimization problem?\n",
    "\n",
    "There are two major problems: \n",
    "1. the product in the integrand\n",
    "2. gradients cannot be past the integral (i.e. we cannot easily compute the gradient to solve the optimization problem). \n",
    "\n",
    "We solve these two problems by: \n",
    "1. pushing the log past the integral so that it can be applied to the integrand (Jensen's Inequality)\n",
    "2. introducing an auxiliary variables $q(Z_n)$ to allow the gradient to be pushed past the integral.\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\ell(\\theta, \\phi) &= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\log \\prod_{n=1}^N\\int_{\\Omega_Z} \\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}q(z_n)\\right) dz\\\\\n",
    "&= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\log\\,\\prod_{n=1}^N\\mathbb{E}_{Z\\sim q(Z)} \\left[  \\frac{p(y_n, Z|\\theta, \\phi)}{q(Z)}\\right]\\\\\n",
    "&= \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\sum_{n=1}^N \\log \\mathbb{E}_{Z\\sim q(Z)} \\left[\\,\\left( \\frac{p(y_n, Z|\\theta, \\phi)}{q(Z)}\\right)\\right]\\\\\n",
    "&\\geq \\underset{\\theta, \\phi, q}{\\mathrm{max}}\\; \\underbrace{\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]}_{ELBO(\\theta, \\phi)}, \\quad (\\text{Jensen's Inequality})\\\\\n",
    "\\end{aligned}\n",
    "\n",
    "We call $\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[ \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z)}\\right)\\right]$ the Evidence Lower Bound (ELBO). Note that maximizing the ELBO will yield a lower bound of the maximum value of the log likelihood. Although **the optimal point of the ELBO may not be the optimal point of the log likelihood**, we nontheless prefer to optimize the ELBO because the gradients, with respect to $\\theta, \\phi$, of the ELBO are easier to compute:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta, \\phi} ELBO(\\theta, \\phi) = \\nabla_{\\theta, \\phi}\\left[ \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]\\right] =  \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\nabla_{\\theta, \\phi} \\left( \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right)\\right]\n",
    "$$\n",
    "\n",
    "Note that we can push the gradient $\\nabla_{\\theta, \\phi}$ past the expectation $\\mathbb{E}_{Z_n\\sim q(Z)}$ since the expectation is not computed with respect to our optimization variables!\n",
    "\n",
    "Rather than optimizing the ELBO over all variables $\\theta, \\phi, q$ (this would be hard), we optimize one set of variables at a time:\n",
    "\n",
    "#### Step I: the M-step\n",
    "Optimize the ELBO with respect to $\\theta, \\phi$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\theta^*, \\phi^* = \\underset{\\theta, \\phi}{\\mathrm{max}}\\; ELBO(\\theta, \\phi, q) &= \\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim q(Z)} \\left[  \\log\\,\\left(\\frac{p(y_n, Z_n|\\theta, \\phi)}{q(Z_n)}\\right)\\right]\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\;  \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\; \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(p(y_n, z_n|\\theta, \\phi)\\right) q(z_n)dz_n - \\underbrace{\\int_{\\Omega_Z} \\log \\left(q(z_n)\\right)q(z_n) dz_n}_{\\text{constant with respect to }\\theta, \\phi}\\\\\n",
    "&\\equiv \\underset{\\theta, \\phi}{\\mathrm{max}}\\;\\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\,\\left(p(y_n, z_n|\\theta, \\phi)\\right) q(z_n)dz_n\\\\\n",
    "&= \\underset{\\theta, \\phi}{\\mathrm{max}}\\;\\sum_{n=1}^N \\mathbb{E}_{Z_n\\sim q(Z)} \\left[ \\log\\left(p(y_n, z_n|\\theta, \\phi)\\right)\\right]\n",
    "\\end{aligned}\n",
    "\n",
    "#### Step II: the E-step\n",
    "Optimize the ELBO with respect to $q$:\n",
    "\n",
    "\\begin{aligned}\n",
    "q^*(Z_n) = \\underset{q}{\\mathrm{argmax}}\\;\\left(\\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; ELBO(\\theta, \\phi, q) \\right) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta^*, \\phi^*, q)\n",
    "\\end{aligned}\n",
    "\n",
    "Rather than optimizing the ELBO with respect to $q$, which seems hard, we will argue that optimizing the ELBO is equivalent to optimizing another function of $q$, one whose optimum is easy for us to compute.\n",
    "\n",
    "**Note:** We can recognize the difference between the log likelihood and the ELBO as a function we've seen:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ell(\\theta, \\phi) - ELBO(\\theta, \\phi, q) &= \\sum_{n=1}^N \\log p(y_n| \\theta, \\phi) - \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&=  \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(p(y_n| \\theta, \\phi)\\right) q(z_n) dz_n - \\sum_{n=1}^N \\int_{\\Omega_Z} \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right)q(z_n) dz_n\\\\\n",
    "&=  \\sum_{n=1}^N \\int_{\\Omega_Z}  \\left(\\log\\left(p(y_n| \\theta, \\phi)\\right) - \\log\\left(\\frac{p(y_n, z_n|\\theta, \\phi)}{q(z_n)}\\right) \\right)q(z_n) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\int_{\\Omega_Z}  \\log\\left(\\frac{p(y_n| \\theta, \\phi)q(z_n)}{p(y_n, z_n|\\theta, \\phi)} \\right)q(z_n) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\int_{\\Omega_Z}  \\log\\left(\\frac{q(z_n)}{p(z_n| y_n, \\theta, \\phi)} \\right)q(z_n) dz_n, \\quad\\left(\\text{Baye's Rule: } \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta, \\phi)} = p(z_n| y_n, \\theta, \\phi)\\right)\\\\\n",
    "&= \\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right].\n",
    "\\end{aligned}\n",
    "\n",
    "Since $\\ell(\\theta, \\phi)$ is a constant, the difference $\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right] = \\ell(\\theta, \\phi) - ELBO(\\theta, \\phi, q)$ descreases when $ELBO(\\theta, \\phi, q)$ increases (and vice versa). Thus, maximizing the ELBO is equivalent to minimizing $D_{\\text{KL}} \\left[ q(Z_n) \\| p(Y_n| Z_n, \\theta, \\phi)\\right]$:\n",
    "\n",
    "$$\n",
    "\\underset{q}{\\mathrm{argmax}}\\, ELBO(\\theta, \\phi, q) = \\underset{q}{\\mathrm{argmin}}\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right].\n",
    "$$\n",
    "\n",
    "Thus, we see that \n",
    "\\begin{aligned}\n",
    "q^*(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta^*, \\phi^*, q) = \\underset{q}{\\mathrm{argmin}}\\sum_{n=1}^N D_{\\text{KL}} \\left[ q(Z_n) \\| p(Z_n| Y_n, \\theta, \\phi)\\right] = p(Z_n| Y_n, \\theta, \\phi)\n",
    "\\end{aligned}\n",
    "\n",
    "That is, we should set the optimal distribution $q$ to be the posterior $p(Z_n| Y_n, \\theta, \\phi)$.\n",
    "\n",
    "#### Iteration\n",
    "Of course, we know that optimizing a function with respect to each variable is not sufficient for finding the global optimum over all the variables, considered together! Thus, performing one E-step and one M-step is not enough to maximize the ELBO. We need to repeat the two steps over and over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Question: Why don't gradients commute with expectation?\n",
    "\n",
    "We have the following property of expectations:\n",
    "\n",
    "$$\n",
    "\\nabla_z \\mathbb{E}_{x\\sim p(x)}[f(x, z)] = \\mathbb{E}_{x\\sim p(x)}[ \\nabla_z f(x, z)] \n",
    "$$\n",
    "\n",
    "That is, when the gradient is with respect to a variable that does not appear in the distribution with respect to which you are taking the expectation, then you can push the gradient past the expectation. \n",
    "\n",
    "**The intuition:** the gradient with respect to $z$ is computing the changes in a function by making infinitesimally small changes to $z$, the expectation is computing the average value of a function by sampling $x$ from a distribution that does not depend on $z$. Each operation is making an independent change to two different variables and hence can be done in any order.\n",
    "\n",
    "Why can't you do this in general? I.e. why is it that, \n",
    "\n",
    "$$ \\nabla_z\\mathbb{E}_{x\\sim p(x|z)}[f(x, z)] \\neq \\mathbb{E}_{x\\sim p(x|z)}[ \\nabla_z f(x, z)]?$$\n",
    "\n",
    "\n",
    "**The intuition:** the gradient with respect to z is computing the changes in a function by making infinitesimally small changes to z, which in turn affects the samples produced by p(x|z), these samples finally affect the output of f. This is a chain of effects and the order matters.\n",
    "\n",
    "**The formal proof:** Consider the following case,\n",
    "\n",
    "$$\n",
    "p(x\\vert z) = (z+1)x^z,\\; x\\in [0, 1]\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "f(x, z) = xzf ( x , z ) = x z.\n",
    "$$\n",
    "\n",
    "Then, we have\n",
    "\n",
    "$$\\nabla_z \\mathbb{E}_{x\\sim p(x|z)} [f(x, z)] = \\nabla_z \\int_0^1 f(x, z) p(x|z) dx = \\nabla_z\\int_0^1 xz \\cdot (z+1)x^z dx = \\nabla_z z (z+1)\\int_0^1x^{z+1} dx = \\nabla_z \\frac{z (z+1)}{z+2} [x^{z+2} ]_0^1 =  \\nabla_z \\frac{z (z+1)}{z+2} = \\frac{z^2 + 4z + 2}{(z+2)^2}\n",
    "$$\n",
    "\n",
    "On the other hand, we have \n",
    "\n",
    "$$\n",
    "\\mathbb{E}_{x\\sim p(x|z)}\\left[ \\nabla_z f(x, z) \\right] = \\int_0^1 \\nabla_z[ xz] (z+1)x^zdx = \\int_0^1(z+1)x^{z+1}dx = \\frac{z+1}{z+2} [x^{z+2}]_0^1 = \\frac{z+1}{z+2}.\n",
    "$$\n",
    "\n",
    "Note that:\n",
    "\n",
    "$$\n",
    "\\nabla_z \\mathbb{E}_{x\\sim p(x|z)} [f(x, z)] =  \\frac{z^2 + 4z+ 2}{(z+2)^2} \\neq \\frac{z+1}{z+2} = \\mathbb{E}_{x\\sim p(x|z)}\\left[ \\nabla_z f(x, z) \\right].\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Question: Why do we need to maximize the ELBO with respect to q?\n",
    "\n",
    "Recall that in the derivation of the ELBO, we first introduced an auxiliary variable q to rewrite the observed log-likelihood:\n",
    "\n",
    "$$\n",
    "\\log p(y|\\theta, \\phi) = \\log \\int_\\Omega p(y, z| \\theta, \\phi) dz = \\log \\int_\\Omega \\frac{p(y, z| \\theta, \\phi}{q(z)}q(z) dz = \\log \\mathbb{E}_{q(z)} \\left[ \\frac{p(y, z|\\theta, \\phi)}{q(z)} \\right]\n",
    "$$\n",
    "\n",
    "Again, the reason why we do this is because: when we eventually take the gradient wrt to $\\theta, \\phi$ during optimization we can use the identity\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta, \\phi} \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right] = \\mathbb{E}_{q(z)}\\left[\\nabla_{\\theta, \\phi}  \\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right] \n",
    "$$\n",
    "\n",
    "***At this point, there is no need to maximize over q***, that is:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta, \\phi, q}\\log \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right] = \\max_{\\theta, \\phi}\\log \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right]\n",
    "$$\n",
    "\n",
    "The $q$ cancels and has no effect on the outcome or process of the optimization (but you can't just choose any $q$ you want - can you see what are the constraints on $q$?).\n",
    "\n",
    "Now, the problem is that the log is on the outside of the expectation. This isn't a problem in the sense that we don't know how to take the derivative of a logarithm of a complex function (this is just the chain rule ),  the problem is that \n",
    "\n",
    "$$\n",
    "\\nabla_{\\phi, \\theta} \\frac{p(y, z|\\theta, \\phi)}{q(z)}\n",
    "$$\n",
    "\n",
    "can be very complex (since p and q are pdf's) and so over all the gradient of the log expectation is not something you can compute roots for. Here is where we push the log inside the expectation using Jensen's inequality:\n",
    "\n",
    "$$\n",
    "\\log \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right]  \\geq \\mathbb{E}_{q(z)}\\left[\\log \\left(\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right)\\right] \\overset{\\text{def}}{=} ELBO(\\phi, \\theta, q)\n",
    "$$\n",
    "\n",
    "When we push the log inside the expectation, we obtain the **E**vidence **L**ower **Bo**und (ELBO). \n",
    "\n",
    "Now, for any choice of $q$, we always have:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta, \\phi}\\log \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right]  \\geq \\max_{\\theta, \\phi}ELBO(\\phi, \\theta, q)\n",
    "$$\n",
    "\n",
    "But the ELBO is not necessarily a tight bound (i.e. maximizing the ELBO can be very far from maximizing the log-likelihood!)! In particular, some choices of $q$ might give you a tighter bound on the log-likelihood than others. Thus, we want to select the $q$ that give us the tightest bound:\n",
    "\n",
    "$$\n",
    "\\max_{\\theta, \\phi}\\log \\mathbb{E}_{q(z)}\\left[\\frac{p(y, z|\\theta, \\phi)}{q(z)}\\right]  \\geq \\max_{\\theta, \\phi, q}ELBO(\\phi, \\theta, q).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Expectation Maximization Algorithm\n",
    "\n",
    "The ***exepectation maximization (EM) algorithm*** maximize the ELBO of the model,\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:150px;\">\n",
    "0. **Initialization:** Pick $\\theta_0$, $\\phi_0$.\n",
    "1. Repeat $i=1, \\ldots, I$ times:\n",
    "\n",
    "  **E-Step:** \n",
    "$$q_{\\text{new}}(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\theta_{\\text{old}}, \\phi_{\\text{old}}, q) = p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})$$\n",
    "\n",
    "  **M-Step:** \n",
    "  \\begin{aligned}\n",
    "  \\theta_{\\text{new}}, \\phi_{\\text{new}} &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; ELBO(\\theta, \\phi, q_{\\text{new}})\\\\\n",
    "  &= \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\phi, \\theta\\right) \\right].\n",
    "\\end{aligned}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## The Auxiliary Function\n",
    "\n",
    "We often denote the expectation in the M-step by $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$\n",
    "$$\n",
    "Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) = \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\phi, \\theta\\right) \\right]\n",
    "$$\n",
    "and call $Q$ the auxiliary function. \n",
    "\n",
    "Frequently, the EM algorithm is equivalently presented as\n",
    "- E-step: compute the auxiliary function: $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$\n",
    "- M-step: maximize the auxiliary function: $\\theta^{\\text{new}}, \\phi^{\\text{new}} = \\underset{\\theta, \\phi}{\\mathrm{argmax}}\\,Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$.\n",
    "\n",
    "The log of the joint distribution $\\prod_{n=1}^N p(Z_n, Y_n, \\theta, \\phi)$ is called the ***complete data log-likelihood*** (since it is the likelihood of both observed and latent variables), whereas $\\log \\prod_{n=1}^N p(Y_n| \\theta, \\phi)$ is called the ***observed data log-likelihood*** (since it is the likelihood of only the observed variable).\n",
    "\n",
    "The auxiliary function presentation of EM is easy to interpret:\n",
    "- In the E-step, you fill in the latent variables in the complete data log-likelihood using \"average\" values, this leaves just an estimate of the observed log-likelihood.\n",
    "- In the M-step, you find parameters $\\phi$ and $\\theta$ that maximizes your estimate of the observed log-likelihood.\n",
    "\n",
    "We chose to derive EM via the ELBO in this lecture because it makes an explicit connection between the EM algorithm for estimating MLE and variational inference method for approximating the posterior of Bayesian models. It is, however, worthwhile to derive EM using the auxiliary function $Q$, as $Q$ makes it convient for us to prove properties of the EM algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Monotonicity and Convergence of EM\n",
    "\n",
    "Before we run off estimating MLE parameters of latent variable models with EM, we need to sanity check two points:\n",
    "\n",
    "1. **(Monotonicity)** we need to know that repeating the E, M-steps will never decrease the ELBO!\n",
    "2. **(Convergence)** we need to know that at some point the EM algorithm will naturally terminate (the algorithm will cease to update the parameters).\n",
    "\n",
    "We first prove the monotonicity of EM. Consider the difference between $\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})$, i.e. the amount by which the log-likelihood can increase or decrease by going from $\\theta^{\\text{old}}, \\phi^{\\text{old}}$ to $\\theta, \\phi$:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}}) &= \\sum_{n=1}^N\\log \\left[ \\frac{p(y_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})} dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n| \\theta^{\\text{old}}, \\phi^{\\text{old}}) p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})}p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}}) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log\\int \\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}}) dz_n\\\\\n",
    "&= \\sum_{n=1}^N \\log \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&\\geq \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\log\\left[\\frac{p(y_n, z_n|\\theta, \\phi)}{p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\right]\\\\\n",
    "&= \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\log  p(y_n, z_n|\\theta, \\phi) - \\log p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})\\right]\\\\\n",
    "&= \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})} \\left[\\log  p(y_n, z_n|\\theta, \\phi)\\right] - \\sum_{n=1}^N  \\mathbb{E}_{p(z_n|y_n, \\theta^{\\text{old}}, \\phi^{\\text{old}})}\\left[ \\log  p(y_n, z_n| \\theta^{\\text{old}}, \\phi^{\\text{old}})\\right]\\\\\n",
    "&= Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\n",
    "\\end{aligned}\n",
    "\n",
    "Thus, when we maximize the gain in log-likelihood going from $\\theta^{\\text{old}}, \\phi^{\\text{old}}$ to $\\theta, \\phi$, we get:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\max} \\left[\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})\\right] \\geq \\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right]\n",
    "\\end{aligned}\n",
    "\n",
    "or equivalently,\n",
    "\n",
    "\\begin{aligned}\n",
    "\\underset{\\theta, \\phi}{\\max} \\left[\\ell(\\theta, \\phi)\\right] - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}}) \\geq \\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right] - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right).\n",
    "\\end{aligned}\n",
    "\n",
    "Note that the above max is always greater than or equal to zero: \n",
    "\n",
    "$$\\underset{\\theta, \\phi}{\\max} \\left[Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)\\right] - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) \\geq 0$$ \n",
    "\n",
    "since we can always maintain the status quo by choosing $theta = \\theta^{\\text{old}}$ $\\phi = \\phi^{\\text{old}}$:\n",
    "\n",
    "$$ Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) - Q\\left(\\theta^{\\text{old}}, \\phi^{\\text{old}}| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right) = 0.$$\n",
    "\n",
    "Thus, we have that by maximizing $Q\\left(\\theta, \\phi| \\theta^{\\text{old}}, \\phi^{\\text{old}}\\right)$, we ensure that $\\ell(\\theta, \\phi) - \\ell(\\theta^{\\text{old}}, \\phi^{\\text{old}})\\geq 0$ in each iteration of EM.\n",
    "\n",
    "\n",
    "If the likelihood of the model is bounded above (i.e. $\\ell(\\theta, \\phi) \\leq M$ for some constant $M$), then EM is guaranteed to convergence. This is because we've proved that EM increases (or maintains) log-likelihood in each iteration, therefore, if $\\ell(\\theta, \\phi)$ is bounded, the process must converge. \n",
    "\n",
    "\n",
    "#### Disclaimer:\n",
    "Although EM converges for bounded likelihoods, it is not guaranteed to converge to the global max of the log-likelihood! Maximizing a lower bound of a function does not necessarily maximize the function itself! Often time, EM converges to local optima of the likelihood function and the point to which it converges may be very sensitive to initialization. We will study this kind of behaviour in more detail when we cover non-convex optimization later in the course.\n",
    "\n",
    "<img src=\"fig/EM.jpg\" style=\"height:350px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "The Gaussian mixture model for the birth weight data has 3 Gaussians with meand $\\mu = [\\mu_1, \\mu_2, \\mu_3]$ and variances $\\sigma^2 = [\\sigma_1^2, \\sigma_2^2, \\sigma_3^2]$, and the model is defined as:\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n | Z_n &\\sim \\mathcal{N}(\\mu_{Z_n}, \\sigma^2_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^3 \\pi_k = 1$. \n",
    "\n",
    "### The E-Step\n",
    "\n",
    "The E-step in EM computes the distribution:\n",
    "$$q_{\\text{new}}(Z_n) = \\underset{q}{\\mathrm{argmax}}\\; ELBO(\\mu_{i-1}, \\sigma^2_{i-1}, \\pi_{i_1}, q) = p(Z_n|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}}).$$ \n",
    "Since $Z_n$ is a label, $p(Z_n|Y_n, \\ldots)$ is a categorical distribution, with the probability of $Z_n=k$ given by:\n",
    "\n",
    "$$\n",
    "p(Z_n = k|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}}) = \\frac{p(y_n|Z_n = k, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})}{\\sum_{k=1}^K p(y|Z_n = k, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})} = \\underbrace{\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}{\\mathcal{Z}}}_{r_{n, k}},\n",
    "$$\n",
    "where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### Setting Up the M-Step\n",
    "\n",
    "The M-step in EM maximize the following: \n",
    "$$\\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; ELBO(\\mu, \\sigma^2, \\pi, q_{\\text{new}}) = \\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma^2, \\pi\\right) \\right].$$\n",
    "\n",
    "If we expand the expectation a little, we get:\n",
    "\\begin{aligned}\n",
    "\\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\sigma^2_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left(p(y_n, Z_n | \\mu, \\sigma^2, \\pi) \\right) \\right] &= \\sum_{n=1}^N \\underbrace{\\sum_{n=1}^K \\log \\left(\\underbrace{ p(y_n| Z_n=k, \\mu, \\sigma^2) p(Z_n=k| \\pi)}_{\\text{factoring the joint }p(y_n, Z_n| \\ldots) } \\right) p(Z_n=k|y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})}_{\\text{expanding the expectation}}\\\\\n",
    "&=\\sum_{n=1}^N \\sum_{k=1}^K \\underbrace{r_{n, k}}_{p(Z_n=k|y_n, \\theta_{\\text{old}}, \\phi_{\\text{old}})} \\left[\\log \\underbrace{\\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)}_{p(y_n| Z_n=k, \\mu, \\sigma^2)}  + \\log \\underbrace{\\pi_k}_{p(Z_n=k| \\pi)}\\right]\\\\\n",
    "&= \\underbrace{\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)}_{\\text{Term #1}} + \\underbrace{\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k}\\pi_k}_{\\text{Term #2}} \n",
    "\\end{aligned}\n",
    "We can maximize each Term #1 and Term #2 individually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### Solving the M-Step\n",
    "\n",
    "We see that the optimization problem in the M-step: $\\mu_{\\text{new}}, \\sigma^2_{\\text{new}}, \\pi_{\\text{new}} = \\underset{\\mu, \\sigma^2, \\pi}{\\mathrm{argmax}}\\; ELBO(\\mu, \\sigma^2, \\pi, q_{\\text{new}})$ is equivalent to two problems\n",
    "\\begin{aligned}\n",
    "&1.\\quad \\underset{\\mu, \\sigma^2}{\\mathrm{argmax}}\\; \\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_k, \\sigma^2_k)\\\\\n",
    "&2.\\quad \\underset{\\pi}{\\mathrm{argmax}}\\; \\sum_{n=1}^N \\sum_{k=1}^K r_{n, k}\\pi_k\n",
    "\\end{aligned}\n",
    "We can solve each optimization problem analytically by finding stationary points of the gradient (or the Lagrangian):\n",
    "- $\\mu_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} y_n$\n",
    "\n",
    "- $\\sigma^2_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} (y_n - \\mu_{\\text{new}})^2$\n",
    "\n",
    "- $\\pi_{\\text{new}} =  \\frac{\\sum_{n=1}^N r_{n, k}}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: EM for the Gaussian Mixture Model of Birth Weight\n",
    "### All Together\n",
    "\n",
    "**Initialization:**\n",
    "Pick any $\\pi$, $\\mu$, $\\sigma^2$\n",
    "\n",
    "**E-Step:**\n",
    "Compute $r_{n, k} = \\displaystyle\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})}{\\mathcal{Z}}$, where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\sigma^2_{k, \\text{old}})$.\n",
    "\n",
    "**M-Step:**\n",
    "Compute model parameters:\n",
    "- $\\mu_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} y_n$\n",
    "\n",
    "- $\\sigma^2_{\\text{new}} = \\frac{1}{ \\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n, k} (y_n - \\mu_{\\text{new}})^2$\n",
    "\n",
    "- $\\pi_{\\text{new}} =  \\frac{\\sum_{n=1}^N r_{n, k}}{N}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Implementing EM for the Gaussian Mixture Model of Birth Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration  0\n",
      "iteration  100\n",
      "iteration  200\n",
      "iteration  300\n",
      "iteration  400\n",
      "iteration  500\n",
      "iteration  600\n",
      "iteration  700\n",
      "iteration  800\n",
      "iteration  900\n",
      "iteration  1000\n",
      "iteration  1100\n",
      "iteration  1200\n",
      "iteration  1300\n",
      "iteration  1400\n"
     ]
    }
   ],
   "source": [
    "#Generate data\n",
    "N = 2000\n",
    "pis = [0.2, 0.6, 0.2]\n",
    "mus = [4.3, 6, 7.8]\n",
    "sigmas = [0.5**2, 0.7**2, 0.5**2]\n",
    "K = 3\n",
    "zs = np.random.choice(np.arange(K), size=N, p=pis)\n",
    "y = np.array([np.random.normal(mus[z], sigmas[z]**0.5, 1)[0] for z in zs])\n",
    "\n",
    "#initialization\n",
    "mu_init = [2, 4, 5]\n",
    "sigma_init = [2., 2., 2.]\n",
    "pi_init = [0.33, 0.33, 0.33]\n",
    "\n",
    "#implement EM\n",
    "mu_current = mu_init\n",
    "sigma_current = sigma_init\n",
    "pi_current = pi_init\n",
    "\n",
    "log_lkhd = []\n",
    "\n",
    "total_iter = 1500\n",
    "threshold = 1e-10\n",
    "\n",
    "mu_diff = 1.\n",
    "pi_diff = 1.\n",
    "sigma_diff = 1.\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < total_iter and mu_diff > threshold and pi_diff > threshold and sigma_diff > threshold:\n",
    "    #E-step\n",
    "    r_unnormalized = np.array([(pi_current[k] *  sp.stats.norm(mu_current[k], sigma_current[k]**0.5).pdf(y)) for k in range(K)]).T\n",
    "    r = r_unnormalized / r_unnormalized.sum(axis=1).reshape((-1, 1))\n",
    "    #M-step\n",
    "    mu_next = np.array([1. / r[:, k].sum() * (r[:, k] * y).sum() for k in range(K)])\n",
    "    sigma_next = np.array([1. / r[:, k].sum() * (r[:, k] * (y - mu_next[k])**2).sum() for k in range(K)])\n",
    "    pi_next = r.sum(axis=0) / r.shape[0]\n",
    "    \n",
    "    #compute log observed likelihood\n",
    "    if i % 100 == 0:\n",
    "        print('iteration ', i)\n",
    "        ll = 0\n",
    "        for n in range(len(y)):\n",
    "            ll += np.log(np.sum([sp.stats.norm(mu_next[k], sigma_next[k]**0.5).pdf(y[n]) * pi_next[k] for k in range(K)])) \n",
    "        log_lkhd.append(ll)\n",
    "        \n",
    "    #convergence check\n",
    "    mu_diff = np.linalg.norm(mu_next - mu_current)\n",
    "    pi_diff = np.linalg.norm(pi_next - pi_current)\n",
    "    sigma_diff = np.linalg.norm(sigma_next - sigma_current)\n",
    "           \n",
    "    #update parameters\n",
    "    mu_current = mu_next\n",
    "    sigma_current = sigma_next\n",
    "    pi_current = pi_next\n",
    "    i += 1\n",
    "    \n",
    "x = np.linspace(y.min(), y.max(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "ax.hist(y, bins=60, density=True, color='gray', alpha=0.5, label='histogram of birth weights')\n",
    "ax.plot(x, pi_current[0] * sp.stats.norm(mu_current[0], sigma_current[0]**0.5).pdf(x), color='red', label='First Gaussian')\n",
    "ax.plot(x, pi_current[1] * sp.stats.norm(mu_current[1], sigma_current[1]**0.5).pdf(x), color='blue', label='Second Gaussian')\n",
    "ax.plot(x, pi_current[2] * sp.stats.norm(mu_current[2], sigma_current[2]**0.5).pdf(x), color='green', label='Third Gaussian')\n",
    "ax.set_title('GMM for Birth Weights')\n",
    "ax.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Example: EM for Gaussian Mixture Models (Multivariate)\n",
    "\n",
    "Recall that our Gaussian mixture model, of $K$ number of Gaussians with means $\\mu = [\\mu_1, \\ldots, \\mu_K]$ and covariances $\\Sigma = [\\Sigma_1, \\ldots, \\Sigma_K]$, is defined as:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n &\\sim \\mathcal{N}(\\mu_{Z_n}, \\Sigma_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "We derive the updates for $\\pi$, $\\mu$ and $\\Sigma$ for the EM algorithm\n",
    "#### E-step:\n",
    "$$\n",
    "q_{\\text{new}} = p(Z_n|y_n, \\pi_{\\text{old}}, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}) = \\frac{p(y_n|Z_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n|\\pi_{\\text{old}})}{\\int p(y_n|z_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(z_n|\\pi_{\\text{old}}) dz_n}\n",
    "$$\n",
    "\n",
    "Since $Z_n$ is a categorical variable, we compute the probability of $Z_n = k$ separately:\n",
    "\n",
    "$$\n",
    "p(Z_n = k|y_n, \\pi_{\\text{old}}, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}) = \\frac{p(y_n|Z_n = k, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})}{\\sum_{k=1}^K p(y|Z_n = k, \\mu_{\\text{old}}, \\Sigma_{\\text{old}})p(Z_n=k | \\pi_{\\text{old}})} = \\underbrace{\\frac{\\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\Sigma_{k, \\text{old}})}{\\mathcal{Z}}}_{r_{n, k}}\n",
    "$$\n",
    "\n",
    "where $\\mathcal{Z} = \\sum_{k=1}^K \\pi_{k, \\text{old}}\\,\\mathcal{N}(y_n; \\mu_{k, \\text{old}}, \\Sigma_{k, \\text{old}})$.\n",
    "\n",
    "Thus, $q_{\\text{new}}(Z_n)$ is a categorical distribution $Cat([r_{n, 1}, \\ldots, r_{n, K}])$.\n",
    "\n",
    "#### M-Step:\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu_{\\text{new}}, \\Sigma_{\\text{new}}, \\pi_{\\text{new}} &= \\underset{\\mu, \\Sigma, \\pi}{\\mathrm{argmax}}\\, \\sum_{n=1}^N\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma \\right) \\right]\\\\\n",
    "&= \\underset{\\mu, \\Sigma, \\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\left[\\log p(y_n | Z_n=k, \\mu, \\Sigma)  + \\log p(Z_n=k | \\pi)\\right]\\\\\n",
    "&= \\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log p(y_n | Z_n=k, \\mu, \\Sigma)  + \\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log p(Z_n=k | \\pi)\\\\\n",
    "&=\\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_{k}, \\Sigma_{k})  + \\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\pi_k\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "We solve the two optimization problems separately. The optimization problem\n",
    "\n",
    "$$\n",
    "\\underset{\\pi}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\pi_k,\\quad \\sum_{k=1}^K \\pi_k = 1\n",
    "$$\n",
    "\n",
    "can be solved using Lagrangian multipliers yielding the solution:\n",
    "\n",
    "$$\n",
    "\\pi_{\\text{new}, k} = \\frac{\\sum_{n=1}^N r_{n, k}}{N}\n",
    "$$\n",
    "\n",
    "The optimization problem \n",
    "\n",
    "$$\n",
    "\\underset{\\mu, \\Sigma}{\\mathrm{argmax}}\\,\\sum_{n=1}^N \\sum_{k=1}^K r_{n, k} \\log \\mathcal{N}(y_n; \\mu_{k}, \\Sigma_{k}) \n",
    "$$\n",
    "\n",
    "can be solved by taking the gradient with respect to $\\mu_k$, $\\Sigma_k$ for each $k$ and computing the stationary points of the gradient (remember to check for the global concavity to ensure you've found a global max). Doing so gives us the optimal points\n",
    "\n",
    "\\begin{aligned}\n",
    "\\mu_{\\text{new},k} &= \\frac{1}{\\sum_{n=1}^N r_{n, k}} \\sum_{n=1}^N r_{n,k}y_n, &\\quad (\\text{weighted sample mean})\\\\\n",
    "\\Sigma_{\\text{new},k} &= \\frac{1}{\\sum_{n=1}^N r_{n, k}}  \\sum_{n=1}^N r_{n,k} (y_n - \\mu_{\\text{new},k})(y_n - \\mu_{\\text{new},k})^\\top, &\\quad (\\text{weighted sample covariance})\n",
    "\\end{aligned}\n",
    "\n",
    "**Exercise:** Verify that the updates for $\\pi_{\\text{new},k}, \\mu_{\\text{new},k}, \\Sigma_{\\text{new},k}$ maximizes $\\mathbb{E}_{Z_n\\sim p(Z_n|Y_n, \\mu_{\\text{old}}, \\Sigma_{\\text{old}}, \\pi_{\\text{old}})}\\left[\\log \\left( p(y_n, Z_n | \\mu, \\sigma \\right) \\right]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sanity Check: Log-Likelihood During Training\n",
    "\n",
    "Remember that ploting the MLE model against actual data is not always an option (e.g. high-dimensional data).\n",
    "\n",
    "A sanity check for that your EM algorithm has been implemented correctly is to plot the observed data log-likelihood over the iterations of the algorithm:\n",
    "$$\n",
    "\\ell_y(\\mu, \\sigma^2, \\pi) = \\sum_{n=1}^N \\log \\sum_{k=1}^K \\mathcal{N}(y_n; \\mu_k, \\sigma_k^2) \\pi_k\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 3))\n",
    "ax.plot(range(len(log_lkhd)), log_lkhd, color='red', alpha=0.5)\n",
    "ax.set_title('observed data log-likelihood over iterations of EM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Expectation Maximization versus Gradient-based Optimization\n",
    "\n",
    "**Pros of EM:**\n",
    "1. No learning rates to adjust\n",
    "2. Don't need to worry about incorporating constraints (i.e. $p(Z_n|Y_n)$ is between 0 and 1)\n",
    "3. Each iteration is guaranteed to increase or maintain observed data log-likelihood\n",
    "4. Is guaranteed to converge to local optimum\n",
    "4. Can be very fast to converge (when parameters are fewer)\n",
    "\n",
    "**Cons of EM:**\n",
    "1. Can get stuck in local optima\n",
    "2. May not maximize observed data log-likelihood (the ELBO is just a lower bound)\n",
    "3. Requires you to do math - you need analytic solutions for E-step and M-step\n",
    "4. May be much slower than fancier gradient-based optimization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "# Review of EM for Latent Variable Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Review: Latent Variable Models\n",
    "\n",
    "Models that include an observed variable $Y$ and at least one unobserved variable $Z$ are called ***latent variable models***. In general, our model can allow $Y$ and $Z$ to interact in many different ways. We have studied models with one type of interaction:\n",
    "\n",
    "<img src=\"fig/graphical_model.jpg\" style=\"height:200px;\">\n",
    "\n",
    "We treat the parameters $\\theta$ and $\\phi$ as *unknown constants*, and we estimate them from the observed data $y_1, \\ldots, y_N$.\n",
    "\n",
    "### Example: Gaussian Mixture Models (GMMs)\n",
    "\n",
    "In a ***Gaussian Mixture Model (GMM)***, we posit that the observed data $Y$ is generated by a mixture, $\\pi=[\\pi_1, \\ldots, \\pi_K]$, of $K$ number of Gaussians with means $\\mu = [\\mu_1, \\ldots, \\mu_K]$ and covariances $\\Sigma = [\\Sigma_1, \\ldots, \\Sigma_K]$. For each observation $Y_n$ the class of the observation $Z_n$ is a latent variable that indicates which of the $K$ Gaussian is responsible for generating $Y_n$:\n",
    "\n",
    "\\begin{aligned}\n",
    "Z_n &\\sim Cat(\\pi),\\\\\n",
    "Y_n | Z_n&\\sim \\mathcal{N}(\\mu_{Z_n}, \\Sigma_{Z_n}),\n",
    "\\end{aligned}\n",
    "where $n=1, \\ldots, N$ and $\\sum_{k=1}^K \\pi_k = 1$. \n",
    "\n",
    "\n",
    "GMMs are examples of ***model based clustering*** - breaking up a data set into natural clusters based on a statistical model fitted to the data.\n",
    "\n",
    "Inference for this model may mean that we want to learn the mean and covariance for each class in the mixture. Or we may want to infer the class membership $z_n$ for each observation $y_n$.\n",
    "\n",
    "### Maximum Likelihood Estimate Inference for Latent Variable Models\n",
    "\n",
    "If we are interested in computing the maximum likelihood estimators of the parameters $\\theta$ and $\\phi$, we need to compute them with respect to the ***observed likelihood*** $p(y| \\theta, \\phi)$ - this is simply because we don't have access to the latent variable values, so we can't evaluate $p(y, z| \\theta, \\phi)$ given values for $\\theta$ and $\\phi$. \n",
    "\n",
    "Just like from before, we maximize the log-likelihood rather than the likelihood due to the simplifying properties of the log function:\n",
    "\n",
    "$$\n",
    "\\theta^*, \\phi^* = \\underset{\\theta, \\phi}{\\text{argmax}}\\; \\ell_y(\\theta, \\phi) = \\underset{\\theta, \\phi}{\\text{argmax}}\\; \\log p(y| \\theta, \\phi) = \\underset{\\theta, \\phi}{\\text{argmax}}\\;\\log \\int p(y, z| \\theta, \\phi)\\, dz\n",
    "$$\n",
    "\n",
    "Maximizing the the above requires taking a gradient,\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta, \\phi} \\log \\int p(y, z| \\theta, \\phi)\\, dz\n",
    "$$\n",
    "\n",
    "but it's not clear how to evaluate this expression. Rewriting the integral as an expectation, it turns out, illuminates the source of the problem:\n",
    "\n",
    "$$\n",
    "\\nabla_{\\theta, \\phi} \\log \\int p(y, z| \\theta, \\phi)\\, dz = \\nabla_{\\theta, \\phi} \\log \\int p(y| z,  \\phi)p(z|\\theta)\\, dz = \\nabla_{\\theta, \\phi} \\log \\mathbb{E}_{z\\sim p(z|\\theta)}[p(y| z,  \\phi)] = \\frac{\\nabla_{\\theta, \\phi} \\mathbb{E}_{z\\sim p(z|\\theta)}[p(y| z,  \\phi)]}{\\mathbb{E}_{z\\sim p(z|\\theta)}[p(y| z,  \\phi)]},\\quad \\text{(chain rule)}\n",
    "$$\n",
    "\n",
    "The above makes it clear that the gradient is not trivial to compute -- the gradient cannot be pushed into the expectation, since the distribution with respect to which we are taking the expectation depends on the optimization variable $\\theta$. \n",
    "\n",
    "To make the gradient computation easier, we make two changes:\n",
    "\n",
    "1. we introduce an auxiliary variable $q(z)$ so that we can replace $\\mathbb{E}_{z\\sim p(z|\\theta)}$ with $\\mathbb{E}_{z\\sim q(z)}$. Note then the latter expectation no longer depends on $\\theta$.\n",
    "\n",
    "2. we push the log inside the expectation using Jensen's inequality.\n",
    "\n",
    "That is, \n",
    "\\begin{aligned}\n",
    "\\ell_y(\\theta, \\phi) &= \\log \\int p(y, z| \\theta, \\phi)\\, dz\\\\\n",
    "&= \\log \\int \\frac{p(y, z| \\theta, \\phi)}{q(z)}q(z)\\, dz\\\\\n",
    "&= \\log \\mathbb{E}_{z\\sim q(z)}\\left[\\frac{p(y, z| \\theta, \\phi)}{q(z)}\\right]\\\\\n",
    "&\\geq \\underbrace{\\mathbb{E}_{z\\sim q(z)} \\left[\\log\\left(\\frac{p(y, z| \\theta, \\phi)}{q(z)}\\right)\\right]}_{ELBO(\\theta, \\phi, q)}\n",
    "\\end{aligned}\n",
    "\n",
    "We have dervied that $ELBO(\\theta, \\phi, q)$ is a lower bound of the log-likelihood $\\ell_y(\\theta, \\phi)$, for any choice of $q$. So rather than maximizing the log-likelihood, we maximize the $ELBO(\\theta, \\phi, q)$, thus ensuring that $\\ell_y(\\theta, \\phi)$ is at least as big:\n",
    "\n",
    "$$\n",
    "\\underset{\\theta, \\phi}{\\max}\\ell_y(\\theta, \\phi)\\geq \\underset{\\theta, \\phi, q}{\\max}ELBO(\\theta, \\phi, q)\n",
    "$$\n",
    "\n",
    "In order to maximize the ELBO, we use coordinate ascent. That is, we take turns maximizing the ELBO with respect to $q$ and then with repect to $\\theta, \\phi$.\n",
    "\n",
    "This algorithm is called ***expectation maximization (EM)***."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
