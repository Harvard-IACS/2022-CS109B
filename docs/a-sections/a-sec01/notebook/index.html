<!DOCTYPE html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8" />
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1, shrink-to-fit=no"
    />
    <meta
      name="description"
      content="Spring 2022 - Harvard University, Institute for Applied Computational Science. Advanced Section 1: Gaussian Mixture Models"
    />
    <meta name="author" content="Pavlos Protopapas & Mark Glickman" />
<meta
  name="keywords"
  content="Gaussian Mixture Model (GMM)"
/>

    <!-- Bootstrap CSS -->
    <link
      rel="stylesheet"
      href="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/css/bootstrap.min.css"
      integrity="sha384-WskhaSGFgHYWDcbwN70/dfYBj47jz9qbsMId/iRN3ewGhXQFZCSftd1LZCfmhktB"
      crossorigin="anonymous"
    />

    <link
      rel="stylesheet"
      href="https://use.fontawesome.com/releases/v5.2.0/css/all.css"
      integrity="sha384-hWVjflwFxL6sNzntih27bfxkr27PmbbK/iSvJ+a4+0owXq79v+lsFkW54bOGbiDQ"
      crossorigin="anonymous"
    />

    <link
      href="https://fonts.googleapis.com/css?family=Roboto+Condensed|Roboto:300,400,700"
      rel="stylesheet"
    />

    <link
      href="https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css"
    />

    <link
      rel="stylesheet"
      href="../../../style/tipuesearch/tipuesearch.css"
    />

    <link
      rel="shortcut icon"
      type="image/x-icon"
      href="../../../style/images/favicon.ico"
    />
    <link rel="stylesheet" href="../../../style/css/iacs.css" />

    <title>Harvard CS109B | Advanced Section 1: Gaussian Mixture Models</title>

    <style>
      .navbar {
        background-color: #c90016
      }
    </style>
  </head>
  <body>
<nav class="navbar navbar-dark navbar-expand-md">
  <div class="container">
    <a class="navbar-brand" href="../../..">
      <img
        class="navbar-brand-logo"
        src="../../../style/images/logo.png"
      />
      <h3 class="course-title">CS109B</h3>
    </a>
    <button
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarsDefault"
      aria-controls="navbarsDefault"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarsDefault">
      <ul class="navbar-nav ml-auto">
        <li class="nav-item">
          <a class="nav-link" href="../../../pages/syllabus.html">Syllabus</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../pages/schedule.html">Schedule</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../pages/materials.html">Materials</a>
        </li>
        <li class="nav-item">
          <a class="nav-link" href="../../../pages/faq.html">FAQ</a>
        </li>
        <form
          class="form-inline my-2"
          action="../../../search.html"
          onsubmit="return validateForm(this.elements['q'].value);"
        >
          <div class="input-group input-group-sm">
            <input
              class="form-control"
              type="text"
              name="q"
              placeholder="Search Topic"
            />
            <div class="input-group-append">
              <button class="btn btn-default" type="submit">
                <i class="fas fa-search"></i>
              </button>
            </div>
          </div>
        </form>
      </ul>
    </div>
    <!-- .collapse navbar-collapse -->
  </div>
  <!-- .container -->
</nav>
    <main id="content" class="container">
 <div>
  <div class="float-left">
    <p>
      Key Word(s):       <a href="../../../pages/materials.html#Gaussian Mixture Model (GMM)"
        >Gaussian Mixture Model (GMM)</a
      >     </p>
  </div>
  <div class="float-right">
    <a href="../../../a-sections/a-sec01/CS109B.ipynb">
      Download Notebook <i class="fas fa-download"></i>
    </a>
  </div>
</div>
<br />
<hr />
 <style type="text/css">/*!
*
* IPython notebook
*
*/
/* CSS font colors for translated ANSI escape sequences */
/* The color values are a mix of
   http://www.xcolors.net/dl/baskerville-ivorylight and
   http://www.xcolors.net/dl/euphrasia */
.ansi-black-fg {
  color: #3E424D;
}
.ansi-black-bg {
  background-color: #3E424D;
}
.ansi-black-intense-fg {
  color: #282C36;
}
.ansi-black-intense-bg {
  background-color: #282C36;
}
.ansi-red-fg {
  color: #E75C58;
}
.ansi-red-bg {
  background-color: #E75C58;
}
.ansi-red-intense-fg {
  color: #B22B31;
}
.ansi-red-intense-bg {
  background-color: #B22B31;
}
.ansi-green-fg {
  color: #00A250;
}
.ansi-green-bg {
  background-color: #00A250;
}
.ansi-green-intense-fg {
  color: #007427;
}
.ansi-green-intense-bg {
  background-color: #007427;
}
.ansi-yellow-fg {
  color: #DDB62B;
}
.ansi-yellow-bg {
  background-color: #DDB62B;
}
.ansi-yellow-intense-fg {
  color: #B27D12;
}
.ansi-yellow-intense-bg {
  background-color: #B27D12;
}
.ansi-blue-fg {
  color: #208FFB;
}
.ansi-blue-bg {
  background-color: #208FFB;
}
.ansi-blue-intense-fg {
  color: #0065CA;
}
.ansi-blue-intense-bg {
  background-color: #0065CA;
}
.ansi-magenta-fg {
  color: #D160C4;
}
.ansi-magenta-bg {
  background-color: #D160C4;
}
.ansi-magenta-intense-fg {
  color: #A03196;
}
.ansi-magenta-intense-bg {
  background-color: #A03196;
}
.ansi-cyan-fg {
  color: #60C6C8;
}
.ansi-cyan-bg {
  background-color: #60C6C8;
}
.ansi-cyan-intense-fg {
  color: #258F8F;
}
.ansi-cyan-intense-bg {
  background-color: #258F8F;
}
.ansi-white-fg {
  color: #C5C1B4;
}
.ansi-white-bg {
  background-color: #C5C1B4;
}
.ansi-white-intense-fg {
  color: #A1A6B2;
}
.ansi-white-intense-bg {
  background-color: #A1A6B2;
}
.ansi-default-inverse-fg {
  color: #FFFFFF;
}
.ansi-default-inverse-bg {
  background-color: #000000;
}
.ansi-bold {
  font-weight: bold;
}
.ansi-underline {
  text-decoration: underline;
}
/* The following styles are deprecated an will be removed in a future version */
.ansibold {
  font-weight: bold;
}
.ansi-inverse {
  outline: 0.5px dotted;
}
/* use dark versions for foreground, to improve visibility */
.ansiblack {
  color: black;
}
.ansired {
  color: darkred;
}
.ansigreen {
  color: darkgreen;
}
.ansiyellow {
  color: #c4a000;
}
.ansiblue {
  color: darkblue;
}
.ansipurple {
  color: darkviolet;
}
.ansicyan {
  color: steelblue;
}
.ansigray {
  color: gray;
}
/* and light for background, for the same reason */
.ansibgblack {
  background-color: black;
}
.ansibgred {
  background-color: red;
}
.ansibggreen {
  background-color: green;
}
.ansibgyellow {
  background-color: yellow;
}
.ansibgblue {
  background-color: blue;
}
.ansibgpurple {
  background-color: magenta;
}
.ansibgcyan {
  background-color: cyan;
}
.ansibggray {
  background-color: gray;
}
div.cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  border-radius: 2px;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
  border-width: 1px;
  border-style: solid;
  border-color: transparent;
  width: 100%;
  padding: 5px;
  /* This acts as a spacer between cells, that is outside the border */
  margin: 0px;
  outline: none;
  position: relative;
  overflow: visible;
}
div.cell:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: transparent;
}
div.cell.jupyter-soft-selected {
  border-left-color: #E3F2FD;
  border-left-width: 1px;
  padding-left: 5px;
  border-right-color: #E3F2FD;
  border-right-width: 1px;
  background: #E3F2FD;
}
@media print {
  div.cell.jupyter-soft-selected {
    border-color: transparent;
  }
}
div.cell.selected,
div.cell.selected.jupyter-soft-selected {
  border-color: #ababab;
}
div.cell.selected:before,
div.cell.selected.jupyter-soft-selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #42A5F5;
}
@media print {
  div.cell.selected,
  div.cell.selected.jupyter-soft-selected {
    border-color: transparent;
  }
}
.edit_mode div.cell.selected {
  border-color: #66BB6A;
}
.edit_mode div.cell.selected:before {
  position: absolute;
  display: block;
  top: -1px;
  left: -1px;
  width: 5px;
  height: calc(100% +  2px);
  content: '';
  background: #66BB6A;
}
@media print {
  .edit_mode div.cell.selected {
    border-color: transparent;
  }
}
.prompt {
  /* This needs to be wide enough for 3 digit prompt numbers: In[100]: */
  min-width: 14ex;
  /* This padding is tuned to match the padding on the CodeMirror editor. */
  padding: 0.4em;
  margin: 0px;
  font-family: monospace;
  text-align: right;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
  /* Don't highlight prompt number selection */
  -webkit-touch-callout: none;
  -webkit-user-select: none;
  -khtml-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
  user-select: none;
  /* Use default cursor */
  cursor: default;
}
@media (max-width: 540px) {
  .prompt {
    text-align: left;
  }
}
div.inner_cell {
  min-width: 0;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_area {
  border: 1px solid #cfcfcf;
  border-radius: 2px;
  background: #f7f7f7;
  line-height: 1.21429em;
}
/* This is needed so that empty prompt areas can collapse to zero height when there
   is no content in the output_subarea and the prompt. The main purpose of this is
   to make sure that empty JavaScript output_subareas have no height. */
div.prompt:empty {
  padding-top: 0;
  padding-bottom: 0;
}
div.unrecognized_cell {
  padding: 5px 5px 5px 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.unrecognized_cell .inner_cell {
  border-radius: 2px;
  padding: 5px;
  font-weight: bold;
  color: red;
  border: 1px solid #cfcfcf;
  background: #eaeaea;
}
div.unrecognized_cell .inner_cell a {
  color: inherit;
  text-decoration: none;
}
div.unrecognized_cell .inner_cell a:hover {
  color: inherit;
  text-decoration: none;
}
@media (max-width: 540px) {
  div.unrecognized_cell > div.prompt {
    display: none;
  }
}
div.code_cell {
  /* avoid page breaking on code cells when printing */
}
@media print {
  div.code_cell {
    page-break-inside: avoid;
  }
}
/* any special styling for code cells that are currently running goes here */
div.input {
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.input {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
/* input_area and input_prompt must match in top border and margin for alignment */
div.input_prompt {
  color: #303F9F;
  border-top: 1px solid transparent;
}
div.input_area > div.highlight {
  margin: 0.4em;
  border: none;
  padding: 0px;
  background-color: transparent;
}
div.input_area > div.highlight > pre {
  margin: 0px;
  border: none;
  padding: 0px;
  background-color: transparent;
}
/* The following gets added to the <head> if it is detected that the user has a
 * monospace font with inconsistent normal/bold/italic height.  See
 * notebookmain.js.  Such fonts will have keywords vertically offset with
 * respect to the rest of the text.  The user should select a better font.
 * See: https://github.com/ipython/ipython/issues/1503
 *
 * .CodeMirror span {
 *      vertical-align: bottom;
 * }
 */
.CodeMirror {
  line-height: 1.21429em;
  /* Changed from 1em to our global default */
  font-size: 14px;
  height: auto;
  /* Changed to auto to autogrow */
  background: none;
  /* Changed from white to allow our bg to show through */
}
.CodeMirror-scroll {
  /*  The CodeMirror docs are a bit fuzzy on if overflow-y should be hidden or visible.*/
  /*  We have found that if it is visible, vertical scrollbars appear with font size changes.*/
  overflow-y: hidden;
  overflow-x: auto;
}
.CodeMirror-lines {
  /* In CM2, this used to be 0.4em, but in CM3 it went to 4px. We need the em value because */
  /* we have set a different line-height and want this to scale with that. */
  /* Note that this should set vertical padding only, since CodeMirror assumes
       that horizontal padding will be set on CodeMirror pre */
  padding: 0.4em 0;
}
.CodeMirror-linenumber {
  padding: 0 8px 0 4px;
}
.CodeMirror-gutters {
  border-bottom-left-radius: 2px;
  border-top-left-radius: 2px;
}
.CodeMirror pre {
  /* In CM3 this went to 4px from 0 in CM2. This sets horizontal padding only,
    use .CodeMirror-lines for vertical */
  padding: 0 0.4em;
  border: 0;
  border-radius: 0;
}
.CodeMirror-cursor {
  border-left: 1.4px solid black;
}
@media screen and (min-width: 2138px) and (max-width: 4319px) {
  .CodeMirror-cursor {
    border-left: 2px solid black;
  }
}
@media screen and (min-width: 4320px) {
  .CodeMirror-cursor {
    border-left: 4px solid black;
  }
}
/*

Original style from softwaremaniacs.org (c) Ivan Sagalaev <Maniac@SoftwareManiacs.Org>
Adapted from GitHub theme

*/
.highlight-base {
  color: #000;
}
.highlight-variable {
  color: #000;
}
.highlight-variable-2 {
  color: #1a1a1a;
}
.highlight-variable-3 {
  color: #333333;
}
.highlight-string {
  color: #BA2121;
}
.highlight-comment {
  color: #408080;
  font-style: italic;
}
.highlight-number {
  color: #080;
}
.highlight-atom {
  color: #88F;
}
.highlight-keyword {
  color: #008000;
  font-weight: bold;
}
.highlight-builtin {
  color: #008000;
}
.highlight-error {
  color: #f00;
}
.highlight-operator {
  color: #AA22FF;
  font-weight: bold;
}
.highlight-meta {
  color: #AA22FF;
}
/* previously not defined, copying from default codemirror */
.highlight-def {
  color: #00f;
}
.highlight-string-2 {
  color: #f50;
}
.highlight-qualifier {
  color: #555;
}
.highlight-bracket {
  color: #997;
}
.highlight-tag {
  color: #170;
}
.highlight-attribute {
  color: #00c;
}
.highlight-header {
  color: blue;
}
.highlight-quote {
  color: #090;
}
.highlight-link {
  color: #00c;
}
/* apply the same style to codemirror */
.cm-s-ipython span.cm-keyword {
  color: #008000;
  font-weight: bold;
}
.cm-s-ipython span.cm-atom {
  color: #88F;
}
.cm-s-ipython span.cm-number {
  color: #080;
}
.cm-s-ipython span.cm-def {
  color: #00f;
}
.cm-s-ipython span.cm-variable {
  color: #000;
}
.cm-s-ipython span.cm-operator {
  color: #AA22FF;
  font-weight: bold;
}
.cm-s-ipython span.cm-variable-2 {
  color: #1a1a1a;
}
.cm-s-ipython span.cm-variable-3 {
  color: #333333;
}
.cm-s-ipython span.cm-comment {
  color: #408080;
  font-style: italic;
}
.cm-s-ipython span.cm-string {
  color: #BA2121;
}
.cm-s-ipython span.cm-string-2 {
  color: #f50;
}
.cm-s-ipython span.cm-meta {
  color: #AA22FF;
}
.cm-s-ipython span.cm-qualifier {
  color: #555;
}
.cm-s-ipython span.cm-builtin {
  color: #008000;
}
.cm-s-ipython span.cm-bracket {
  color: #997;
}
.cm-s-ipython span.cm-tag {
  color: #170;
}
.cm-s-ipython span.cm-attribute {
  color: #00c;
}
.cm-s-ipython span.cm-header {
  color: blue;
}
.cm-s-ipython span.cm-quote {
  color: #090;
}
.cm-s-ipython span.cm-link {
  color: #00c;
}
.cm-s-ipython span.cm-error {
  color: #f00;
}
.cm-s-ipython span.cm-tab {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAADAAAAAMCAYAAAAkuj5RAAAAAXNSR0IArs4c6QAAAGFJREFUSMft1LsRQFAQheHPowAKoACx3IgEKtaEHujDjORSgWTH/ZOdnZOcM/sgk/kFFWY0qV8foQwS4MKBCS3qR6ixBJvElOobYAtivseIE120FaowJPN75GMu8j/LfMwNjh4HUpwg4LUAAAAASUVORK5CYII=);
  background-position: right;
  background-repeat: no-repeat;
}
div.output_wrapper {
  /* this position must be relative to enable descendents to be absolute within it */
  position: relative;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
  z-index: 1;
}
/* class for the output area when it should be height-limited */
div.output_scroll {
  /* ideally, this would be max-height, but FF barfs all over that */
  height: 24em;
  /* FF needs this *and the wrapper* to specify full width, or it will shrinkwrap */
  width: 100%;
  overflow: auto;
  border-radius: 2px;
  -webkit-box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  box-shadow: inset 0 2px 8px rgba(0, 0, 0, 0.8);
  display: block;
}
/* output div while it is collapsed */
div.output_collapsed {
  margin: 0px;
  padding: 0px;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
div.out_prompt_overlay {
  height: 100%;
  padding: 0px 0.4em;
  position: absolute;
  border-radius: 2px;
}
div.out_prompt_overlay:hover {
  /* use inner shadow to get border that is computed the same on WebKit/FF */
  -webkit-box-shadow: inset 0 0 1px #000;
  box-shadow: inset 0 0 1px #000;
  background: rgba(240, 240, 240, 0.5);
}
div.output_prompt {
  color: #D84315;
}
/* This class is the outer container of all output sections. */
div.output_area {
  padding: 0px;
  page-break-inside: avoid;
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
div.output_area .MathJax_Display {
  text-align: left !important;
}
div.output_area 
div.output_area 
div.output_area img,
div.output_area svg {
  max-width: 100%;
  height: auto;
}
div.output_area img.unconfined,
div.output_area svg.unconfined {
  max-width: none;
}
div.output_area .mglyph > img {
  max-width: none;
}
/* This is needed to protect the pre formating from global settings such
   as that of bootstrap */
.output {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: vertical;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: vertical;
  -moz-box-align: stretch;
  display: box;
  box-orient: vertical;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: column;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.output_area {
    /* Old browsers */
    display: -webkit-box;
    -webkit-box-orient: vertical;
    -webkit-box-align: stretch;
    display: -moz-box;
    -moz-box-orient: vertical;
    -moz-box-align: stretch;
    display: box;
    box-orient: vertical;
    box-align: stretch;
    /* Modern browsers */
    display: flex;
    flex-direction: column;
    align-items: stretch;
  }
}
div.output_area pre {
  margin: 0;
  padding: 1px 0 1px 0;
  border: 0;
  vertical-align: baseline;
  color: black;
  background-color: transparent;
  border-radius: 0;
}
/* This class is for the output subarea inside the output_area and after
   the prompt div. */
div.output_subarea {
  overflow-x: auto;
  padding: 0.4em;
  /* Old browsers */
  -webkit-box-flex: 1;
  -moz-box-flex: 1;
  box-flex: 1;
  /* Modern browsers */
  flex: 1;
  max-width: calc(100% - 14ex);
}
div.output_scroll div.output_subarea {
  overflow-x: visible;
}
/* The rest of the output_* classes are for special styling of the different
   output types */
/* all text output has this class: */
div.output_text {
  text-align: left;
  color: #000;
  /* This has to match that of the the CodeMirror class line-height below */
  line-height: 1.21429em;
}
/* stdout/stderr are 'text' as well as 'stream', but execute_result/error are *not* streams */
div.output_stderr {
  background: #fdd;
  /* very light red background for stderr */
}
div.output_latex {
  text-align: left;
}
/* Empty output_javascript divs should have no height */
div.output_javascript:empty {
  padding: 0;
}
.js-error {
  color: darkred;
}
/* raw_input styles */
div.raw_input_container {
  line-height: 1.21429em;
  padding-top: 5px;
}
pre.raw_input_prompt {
  /* nothing needed here. */
}
input.raw_input {
  font-family: monospace;
  font-size: inherit;
  color: inherit;
  width: auto;
  /* make sure input baseline aligns with prompt */
  vertical-align: baseline;
  /* padding + margin = 0.5em between prompt and cursor */
  padding: 0em 0.25em;
  margin: 0em 0.25em;
}
input.raw_input:focus {
  box-shadow: none;
}
p.p-space {
  margin-bottom: 10px;
}
div.output_unrecognized {
  padding: 5px;
  font-weight: bold;
  color: red;
}
div.output_unrecognized a {
  color: inherit;
  text-decoration: none;
}
div.output_unrecognized a:hover {
  color: inherit;
  text-decoration: none;
}
.rendered_html {
  color: #000;
  /* any extras will just be numbers: */
}



.rendered_html :link {
  text-decoration: underline;
}
.rendered_html :visited {
  text-decoration: underline;
}






.rendered_html h1:first-child {
  margin-top: 0.538em;
}
.rendered_html h2:first-child {
  margin-top: 0.636em;
}
.rendered_html h3:first-child {
  margin-top: 0.777em;
}
.rendered_html h4:first-child {
  margin-top: 1em;
}
.rendered_html h5:first-child {
  margin-top: 1em;
}
.rendered_html h6:first-child {
  margin-top: 1em;
}
.rendered_html ul:not(.list-inline),
.rendered_html ol:not(.list-inline) {
  padding-left: 2em;
}








.rendered_html * + ul {
  margin-top: 1em;
}
.rendered_html * + ol {
  margin-top: 1em;
}





.rendered_html pre,




.rendered_html tr,
.rendered_html th,


.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}
.rendered_html * + table {
  margin-top: 1em;
}

.rendered_html * + p {
  margin-top: 1em;
}

.rendered_html * + img {
  margin-top: 1em;
}
.rendered_html img,

.rendered_html img.unconfined,


.rendered_html * + .alert {
  margin-top: 1em;
}
[dir="rtl"] 
div.text_cell {
  /* Old browsers */
  display: -webkit-box;
  -webkit-box-orient: horizontal;
  -webkit-box-align: stretch;
  display: -moz-box;
  -moz-box-orient: horizontal;
  -moz-box-align: stretch;
  display: box;
  box-orient: horizontal;
  box-align: stretch;
  /* Modern browsers */
  display: flex;
  flex-direction: row;
  align-items: stretch;
}
@media (max-width: 540px) {
  div.text_cell > div.prompt {
    display: none;
  }
}
div.text_cell_render {
  /*font-family: "Helvetica Neue", Arial, Helvetica, Geneva, sans-serif;*/
  outline: none;
  resize: none;
  width: inherit;
  border-style: none;
  padding: 0.5em 0.5em 0.5em 0.4em;
  color: #000;
  box-sizing: border-box;
  -moz-box-sizing: border-box;
  -webkit-box-sizing: border-box;
}
a.anchor-link:link {
  text-decoration: none;
  padding: 0px 20px;
  visibility: hidden;
}
h1:hover .anchor-link,
h2:hover .anchor-link,
h3:hover .anchor-link,
h4:hover .anchor-link,
h5:hover .anchor-link,
h6:hover .anchor-link {
  visibility: visible;
}
.text_cell.rendered .input_area {
  display: none;
}
.text_cell.rendered 
.text_cell.rendered .rendered_html tr,
.text_cell.rendered .rendered_html th,
.text_cell.rendered 
.text_cell.unrendered .text_cell_render {
  display: none;
}
.text_cell .dropzone .input_area {
  border: 2px dashed #bababa;
  margin: -1px;
}
.cm-header-1,
.cm-header-2,
.cm-header-3,
.cm-header-4,
.cm-header-5,
.cm-header-6 {
  font-weight: bold;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
}
.cm-header-1 {
  font-size: 185.7%;
}
.cm-header-2 {
  font-size: 157.1%;
}
.cm-header-3 {
  font-size: 128.6%;
}
.cm-header-4 {
  font-size: 110%;
}
.cm-header-5 {
  font-size: 100%;
  font-style: italic;
}
.cm-header-6 {
  font-size: 100%;
  font-style: italic;
}
</style>
<style type="text/css">pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.highlight .hll { background-color: #ffffcc }
.highlight { background: #f8f8f8; }
.highlight .c { color: #3D7B7B; font-style: italic } /* Comment */
.highlight .err { border: 1px solid #FF0000 } /* Error */
.highlight .k { color: #008000; font-weight: bold } /* Keyword */
.highlight .o { color: #666666 } /* Operator */
.highlight .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.highlight .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.highlight .cp { color: #9C6500 } /* Comment.Preproc */
.highlight .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.highlight .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.highlight .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.highlight .gd { color: #A00000 } /* Generic.Deleted */
.highlight .ge { font-style: italic } /* Generic.Emph */
.highlight .gr { color: #E40000 } /* Generic.Error */
.highlight .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.highlight .gi { color: #008400 } /* Generic.Inserted */
.highlight .go { color: #717171 } /* Generic.Output */
.highlight .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.highlight .gs { font-weight: bold } /* Generic.Strong */
.highlight .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.highlight .gt { color: #0044DD } /* Generic.Traceback */
.highlight .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.highlight .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.highlight .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.highlight .kp { color: #008000 } /* Keyword.Pseudo */
.highlight .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.highlight .kt { color: #B00040 } /* Keyword.Type */
.highlight .m { color: #666666 } /* Literal.Number */
.highlight .s { color: #BA2121 } /* Literal.String */
.highlight .na { color: #687822 } /* Name.Attribute */
.highlight .nb { color: #008000 } /* Name.Builtin */
.highlight .nc { color: #0000FF; font-weight: bold } /* Name.Class */
.highlight .no { color: #880000 } /* Name.Constant */
.highlight .nd { color: #AA22FF } /* Name.Decorator */
.highlight .ni { color: #717171; font-weight: bold } /* Name.Entity */
.highlight .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.highlight .nf { color: #0000FF } /* Name.Function */
.highlight .nl { color: #767600 } /* Name.Label */
.highlight .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */
.highlight .nt { color: #008000; font-weight: bold } /* Name.Tag */
.highlight .nv { color: #19177C } /* Name.Variable */
.highlight .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */
.highlight .w { color: #bbbbbb } /* Text.Whitespace */
.highlight .mb { color: #666666 } /* Literal.Number.Bin */
.highlight .mf { color: #666666 } /* Literal.Number.Float */
.highlight .mh { color: #666666 } /* Literal.Number.Hex */
.highlight .mi { color: #666666 } /* Literal.Number.Integer */
.highlight .mo { color: #666666 } /* Literal.Number.Oct */
.highlight .sa { color: #BA2121 } /* Literal.String.Affix */
.highlight .sb { color: #BA2121 } /* Literal.String.Backtick */
.highlight .sc { color: #BA2121 } /* Literal.String.Char */
.highlight .dl { color: #BA2121 } /* Literal.String.Delimiter */
.highlight .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.highlight .s2 { color: #BA2121 } /* Literal.String.Double */
.highlight .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.highlight .sh { color: #BA2121 } /* Literal.String.Heredoc */
.highlight .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.highlight .sx { color: #008000 } /* Literal.String.Other */
.highlight .sr { color: #A45A77 } /* Literal.String.Regex */
.highlight .s1 { color: #BA2121 } /* Literal.String.Single */
.highlight .ss { color: #19177C } /* Literal.String.Symbol */
.highlight .bp { color: #008000 } /* Name.Builtin.Pseudo */
.highlight .fm { color: #0000FF } /* Name.Function.Magic */
.highlight .vc { color: #19177C } /* Name.Variable.Class */
.highlight .vg { color: #19177C } /* Name.Variable.Global */
.highlight .vi { color: #19177C } /* Name.Variable.Instance */
.highlight .vm { color: #19177C } /* Name.Variable.Magic */
.highlight .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Advanced-Section:-Gaussian-Mixture-Models">Advanced Section: Gaussian Mixture Models<a class="anchor-link" href="#Advanced-Section:-Gaussian-Mixture-Models">¶</a></h1><h2 id="CS-109B">CS 109B<a class="anchor-link" href="#CS-109B">¶</a></h2><h3 id="Spring,-2021">Spring, 2021<a class="anchor-link" href="#Spring,-2021">¶</a></h3>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><img src="fig/logos.jpg" style="height:150px;" /></p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [1]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">### Import basic libraries</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy</span> <span class="k">as</span> <span class="nn">sp</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span> <span class="k">as</span> <span class="nn">sk</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="o">%</span><span class="k">matplotlib</span> inline
</pre></div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Motivation-for-Latent-Variable-Models">Motivation for Latent Variable Models<a class="anchor-link" href="#Motivation-for-Latent-Variable-Models">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Model-for-Birth-Weights">A Model for Birth Weights<a class="anchor-link" href="#A-Model-for-Birth-Weights">¶</a></h2><p>Recall our model for birth weigths, $Y_1,\ldots, Y_N$. We <em>posited</em> that the birth weights are iid normally distributed with known $\sigma^2$, $Y_n \sim \mathcal{N}(\mu, 1)$.</p>
<p>Compare the maximum likelihood model and the Bayesian model for bith weight. Which model would you use to make clinical decisions? What's hard about this comparison?</p>
<p><img src="fig/compare.jpg" style="height:300px;" /></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="A-Similarity-Measure-for-Distributions:-Kullback–Leibler-Divergence">A Similarity Measure for Distributions: Kullback–Leibler Divergence<a class="anchor-link" href="#A-Similarity-Measure-for-Distributions:-Kullback–Leibler-Divergence">¶</a></h2><p>Visually comparing models to the <strong><em>empirical distribution</em></strong> of the data is impractical. Fortunately, there are a large number of quantitative measures for comparing two distributions, these are called <strong><em>divergence measures</em></strong>. For example, the <strong><em>Kullback–Leibler (KL) Divergence</em></strong> is defined for two distributions $p(\theta)$ and $q(\theta)$ supported on $\Theta$ as:</p>
$$
D_{\text{KL}}[q \,\|\, p] = \int_{\Theta} \log\left[\frac{q(\theta)}{p(\theta)} \right] q(\theta)d\theta
$$<p>The KL-divergence $D_{\text{KL}}[q \,\|\, p]$ is bounded below by 0, which happens if and only if $q=p$.
The KL-divergence has information theoretic interpretations that we will explore later in the course.</p>
<p><strong>Note:</strong> The KL-divergence is defined in terms of the pdf's of $p$ and $q$. If $p$ is a distribution from which we only have samples and not the pdf (like the empirical distribution), we can nontheless estimate $D_{\text{KL}}[q \,\|\, p]$. Techniques that estimate the KL-divergence from samples are called <strong><em>non-parametric</em></strong>. We will use them later in the course.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Why-is-the-KL-bounded-below-by-0?">Why is the KL bounded below by 0?<a class="anchor-link" href="#Why-is-the-KL-bounded-below-by-0?">¶</a></h2><p>First let's see why the answer isn't obvious. Recall that the <strong><em>KL divergence is the expected log ratio between two distribution</em></strong>:</p>
$$
D_{\text{KL}} [q\| p] = \mathbb{E}_{q}\left[ \log \frac{q}{p}\right]
$$<p>Now, we know that when $q$ is less than $p$ (i.e. $q/p < 1$) then the log can be an arbitrarily negative number. So it's not immediately obvious that the expected value of this fraction should always be non-negative!</p>
<p><strong>An intuitive explanation:</strong></p>
<p>Let the blue curve be q and the red be p. We have $q < p$ from $(-\infty, 55)$, on this part of the domain $\log(q/p)$ is negative. On $[55, \infty)$, $\log(q/p)$ is nonnegative.</p>
<p>However, since we are sampling from $q$, and $q$'s mass is largely over $[55, \infty)$, the log fraction $\log(q/p$) will tend to be nonnegative.</p>
<p><img src="fig/kl.png" style="height:300px;" /></p>
<p><strong>A formal argument:</strong></p>
<p>There are many proofs of the non-negativity of the KL. Ranging from the very complex to the very simple. Here is one that just involves a bit of algebra:</p>
<p>We want to show that $D_{\text{KL}}[q\|p] \geq 0$. Instead we'll show, equivalently, that $-D_{\text{KL}}[q\|p] \leq 0$ (we're choosing show the statement about the negative KL, just so we can flip the fraction on the inside of the log and cancel terms):</p>
<p><img src="fig/derivation.png" style="height:300px;" /></p>
<p><img src="fig/log.png" style="height:300px;" /></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Class-Membership-as-a-Latent-Variable">Class Membership as a Latent Variable<a class="anchor-link" href="#Class-Membership-as-a-Latent-Variable">¶</a></h2><p>We observe that there are three <strong><em>clusters</em></strong> in the data. We posit that there are three <strong><em>classes</em></strong> of infants in the study: infants with low birth weights, infants with normal birth weights and those with high birth weights. The numbers of infants in the classes are not equal.</p>
<p>For each observation $Y_n$, we model its class membership $Z_n$ as a categorical variable,</p>
$$Z_n\sim Cat(\pi),$$<p>where $\pi_i$ in $\pi = [\pi_1, \pi_2, \pi_3]$ is the class proportion. Note that we don't have the class membership $Z_n$ in the data! So $Z_n$ is called a <strong><em>latent variable</em></strong>.</p>
<p>Depending on the class, the $n$-th birth weight $Y_n$ will have a different normal distribution,</p>
$$
Y_n | Z_n \sim \mathcal{N}\left(\mu_{Z_n}, \sigma^2_{Z_n}\right)
$$<p>where $\mu_{Z_n}$ is one of the three class means $[\mu_1, \mu_2, \mu_3]$ and $\sigma^2_{Z_n}$ is one of the three class variances $[\sigma^2_1, \sigma^2_2, \sigma^2_3]$.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Common-Latent-Variable-Models">Common Latent Variable Models<a class="anchor-link" href="#Common-Latent-Variable-Models">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Latent-Variable-Models">Latent Variable Models<a class="anchor-link" href="#Latent-Variable-Models">¶</a></h2><p>Models that include an observed variable $Y$ and at least one unobserved variable $Z$ are called <strong><em>latent variable models</em></strong>. In general, our model can allow $Y$ and $Z$ to interact in many different ways. Today, we will study models with one type of interaction:</p>
<p><img src="fig/graphical_model.jpg" style="height:300px;" /></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Gaussian-Mixture-Models-(GMMs)">Gaussian Mixture Models (GMMs)<a class="anchor-link" href="#Gaussian-Mixture-Models-(GMMs)">¶</a></h2><p>In a <strong><em>Gaussian Mixture Model (GMM)</em></strong>, we posit that the observed data $Y$ is generated by a mixture, $\pi=[\pi_1, \ldots, \pi_K]$, of $K$ number of Gaussians with means $\mu = [\mu_1, \ldots, \mu_K]$ and covariances $\Sigma = [\Sigma_1, \ldots, \Sigma_K]$. For each observation $Y_n$ the class of the observation $Z_n$ is a latent variable that indicates which of the $K$ Gaussian is responsible for generating $Y_n$:</p>
\begin{aligned}
Z_n &\sim Cat(\pi),\\
Y_n | Z_n&\sim \mathcal{N}(\mu_{Z_n}, \Sigma_{Z_n}),
\end{aligned}<p>where $n=1, \ldots, N$ and $\sum_{k=1}^K \pi_k = 1$.</p>
<p>GMMs are examples of <strong><em>model based clustering</em></strong> - breaking up a data set into natural clusters based on a statistical model fitted to the data.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Item-Response-Models">Item-Response Models<a class="anchor-link" href="#Item-Response-Models">¶</a></h2><p>In <strong><em>item-response models</em></strong>, we measure an real-valued unobserved trait $Z$ of a subject by performing a series of experiments with binary observable outcomes, $Y$:</p>
\begin{aligned}
Z_n &\sim \mathcal{N}(\mu, \sigma^2),\\
\theta_n &= g(Z_n)\\
Y_n|Z_n &\sim Ber(\theta_n),
\end{aligned}<p>where $n=1, \ldots, N$ and $g$ is some fixed function of $Z_n$.</p>
<h4 id="Applications">Applications<a class="anchor-link" href="#Applications">¶</a></h4><p>Item response models are used to model the way "underlying intelligence" $Z$ relates to scores $Y$ on IQ tests.</p>
<p>Item response models can also be used to model the way "suicidality" $Z$ relates to answers on mental health surveys. Building a good model may help to infer when a patient is at psychiatric risk based on in-take surveys at points of care through out the health-care system.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Factor-Analysis-Models">Factor Analysis Models<a class="anchor-link" href="#Factor-Analysis-Models">¶</a></h2><p>In <strong><em>factor analysis models</em></strong>, we posit that the observed data $Y$ with many measurements is generated by a small set of unobserved factors $Z$:</p>
\begin{aligned}
Z_n &\sim \mathcal{N}(0, I),\\
Y_n|Z_n &\sim \mathcal{N}(\mu + \Lambda Z_n, \Phi),
\end{aligned}<p>where $n=1, \ldots, N$, $Z_n\in \mathbb{R}^{D'}$ and $Y_n\in \mathbb{R}^{D}$. We typically assume that $D'$ is much smaller than $D$.</p>
<h4 id="Applications">Applications<a class="anchor-link" href="#Applications">¶</a></h4><p>Factor analysis models are useful for biomedical data, where we typically measure a large number of characteristics of a patient (e.g. blood pressure, heart rate, etc), but these characteristics are all generated by a small list of health factors (e.g. diabetes, cancer, hypertension etc). Building a good model means we may be able to infer the list of health factors of a patient from their observed measurements.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Maximum-Likelihood-Estimation-for-Latent-Variable-Models:-Expectation-Maximization">Maximum Likelihood Estimation for Latent Variable Models: Expectation Maximization<a class="anchor-link" href="#Maximum-Likelihood-Estimation-for-Latent-Variable-Models:-Expectation-Maximization">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Expectation-Maximization:-Estimating-the-MLE-for-Latent-Variable-Models">Expectation Maximization: Estimating the MLE for Latent Variable Models<a class="anchor-link" href="#Expectation-Maximization:-Estimating-the-MLE-for-Latent-Variable-Models">¶</a></h2><p>Given a latent variable model $p(Y, Z| \phi, \theta) = p(Y | Z, \phi) p(Z|\theta)$, we are interested computing the MLE of parameters $\phi$ and $\theta$:</p>
\begin{aligned}
\theta_{\text{MLE}}, \phi_{\text{MLE}} &= \underset{\theta, \phi}{\mathrm{argmax}}\; \ell(\theta, \phi)\\
&= \underset{\theta, \phi}{\mathrm{argmax}}\; \log \prod_{n=1}^N \int_{\Omega_Z}  p(y_n, z_n | \theta, \phi) dz\\
&= \underset{\theta, \phi}{\mathrm{argmax}}\; \log \prod_{n=1}^N \int_{\Omega_Z}  p(y_n| z_n, \phi)p(z_n| \theta) dz
\end{aligned}<p>where $\Omega_Z$ is the domain of $Z$.
Why is this an hard optimization problem?</p>
<p>There are two major problems:</p>
<ol>
<li>the product in the integrand</li>
<li>gradients cannot be past the integral (i.e. we cannot easily compute the gradient to solve the optimization problem). </li>
</ol>
<p>We solve these two problems by:</p>
<ol>
<li>pushing the log past the integral so that it can be applied to the integrand (Jensen's Inequality)</li>
<li>introducing an auxiliary variables $q(Z_n)$ to allow the gradient to be pushed past the integral.</li>
</ol>
\begin{aligned}
\underset{\theta, \phi}{\mathrm{max}}\; \ell(\theta, \phi) &= \underset{\theta, \phi, q}{\mathrm{max}}\; \log \prod_{n=1}^N\int_{\Omega_Z} \left(\frac{p(y_n, z_n|\theta, \phi)}{q(z_n)}q(z_n)\right) dz\\
&= \underset{\theta, \phi, q}{\mathrm{max}}\; \log\,\prod_{n=1}^N\mathbb{E}_{Z\sim q(Z)} \left[  \frac{p(y_n, Z|\theta, \phi)}{q(Z)}\right]\\
&= \underset{\theta, \phi, q}{\mathrm{max}}\; \sum_{n=1}^N \log \mathbb{E}_{Z\sim q(Z)} \left[\,\left( \frac{p(y_n, Z|\theta, \phi)}{q(Z)}\right)\right]\\
&\geq \underset{\theta, \phi, q}{\mathrm{max}}\; \underbrace{\sum_{n=1}^N\mathbb{E}_{Z_n\sim q(Z)} \left[  \log\,\left(\frac{p(y_n, Z_n|\theta, \phi)}{q(Z_n)}\right)\right]}_{ELBO(\theta, \phi)}, \quad (\text{Jensen's Inequality})\\
\end{aligned}<p>We call $\sum_{n=1}^N\mathbb{E}_{Z_n\sim q(Z)} \left[ \log\,\left(\frac{p(y_n, Z_n|\theta, \phi)}{q(Z)}\right)\right]$ the Evidence Lower Bound (ELBO). Note that maximizing the ELBO will yield a lower bound of the maximum value of the log likelihood. Although <strong>the optimal point of the ELBO may not be the optimal point of the log likelihood</strong>, we nontheless prefer to optimize the ELBO because the gradients, with respect to $\theta, \phi$, of the ELBO are easier to compute:</p>
$$
\nabla_{\theta, \phi} ELBO(\theta, \phi) = \nabla_{\theta, \phi}\left[ \sum_{n=1}^N\mathbb{E}_{Z_n\sim q(Z)} \left[  \log\,\left(\frac{p(y_n, Z_n|\theta, \phi)}{q(Z_n)}\right)\right]\right] =  \sum_{n=1}^N\mathbb{E}_{Z_n\sim q(Z)} \left[  \nabla_{\theta, \phi} \left( \log\,\left(\frac{p(y_n, Z_n|\theta, \phi)}{q(Z_n)}\right)\right)\right]
$$<p>Note that we can push the gradient $\nabla_{\theta, \phi}$ past the expectation $\mathbb{E}_{Z_n\sim q(Z)}$ since the expectation is not computed with respect to our optimization variables!</p>
<p>Rather than optimizing the ELBO over all variables $\theta, \phi, q$ (this would be hard), we optimize one set of variables at a time:</p>
<h4 id="Step-I:-the-M-step">Step I: the M-step<a class="anchor-link" href="#Step-I:-the-M-step">¶</a></h4><p>Optimize the ELBO with respect to $\theta, \phi$:</p>
\begin{aligned}
\theta^*, \phi^* = \underset{\theta, \phi}{\mathrm{max}}\; ELBO(\theta, \phi, q) &= \underset{\theta, \phi}{\mathrm{max}}\; \sum_{n=1}^N\mathbb{E}_{Z_n\sim q(Z)} \left[  \log\,\left(\frac{p(y_n, Z_n|\theta, \phi)}{q(Z_n)}\right)\right]\\
&= \underset{\theta, \phi}{\mathrm{max}}\;  \sum_{n=1}^N \int_{\Omega_Z} \log\,\left(\frac{p(y_n, z_n|\theta, \phi)}{q(z_n)}\right)q(z_n) dz_n\\
&= \underset{\theta, \phi}{\mathrm{max}}\; \sum_{n=1}^N \int_{\Omega_Z} \log\,\left(p(y_n, z_n|\theta, \phi)\right) q(z_n)dz_n - \underbrace{\int_{\Omega_Z} \log \left(q(z_n)\right)q(z_n) dz_n}_{\text{constant with respect to }\theta, \phi}\\
&\equiv \underset{\theta, \phi}{\mathrm{max}}\;\sum_{n=1}^N \int_{\Omega_Z} \log\,\left(p(y_n, z_n|\theta, \phi)\right) q(z_n)dz_n\\
&= \underset{\theta, \phi}{\mathrm{max}}\;\sum_{n=1}^N \mathbb{E}_{Z_n\sim q(Z)} \left[ \log\left(p(y_n, z_n|\theta, \phi)\right)\right]
\end{aligned}<h4 id="Step-II:-the-E-step">Step II: the E-step<a class="anchor-link" href="#Step-II:-the-E-step">¶</a></h4><p>Optimize the ELBO with respect to $q$:</p>
\begin{aligned}
q^*(Z_n) = \underset{q}{\mathrm{argmax}}\;\left(\underset{\theta, \phi}{\mathrm{argmax}}\; ELBO(\theta, \phi, q) \right) = \underset{q}{\mathrm{argmax}}\; ELBO(\theta^*, \phi^*, q)
\end{aligned}<p>Rather than optimizing the ELBO with respect to $q$, which seems hard, we will argue that optimizing the ELBO is equivalent to optimizing another function of $q$, one whose optimum is easy for us to compute.</p>
<p><strong>Note:</strong> We can recognize the difference between the log likelihood and the ELBO as a function we've seen:</p>
\begin{aligned}
\ell(\theta, \phi) - ELBO(\theta, \phi, q) &= \sum_{n=1}^N \log p(y_n| \theta, \phi) - \sum_{n=1}^N \int_{\Omega_Z} \log\left(\frac{p(y_n, z_n|\theta, \phi)}{q(z_n)}\right)q(z_n) dz_n\\
&=  \sum_{n=1}^N \int_{\Omega_Z} \log\left(p(y_n| \theta, \phi)\right) q(z_n) dz_n - \sum_{n=1}^N \int_{\Omega_Z} \log\left(\frac{p(y_n, z_n|\theta, \phi)}{q(z_n)}\right)q(z_n) dz_n\\
&=  \sum_{n=1}^N \int_{\Omega_Z}  \left(\log\left(p(y_n| \theta, \phi)\right) - \log\left(\frac{p(y_n, z_n|\theta, \phi)}{q(z_n)}\right) \right)q(z_n) dz_n\\
&= \sum_{n=1}^N \int_{\Omega_Z}  \log\left(\frac{p(y_n| \theta, \phi)q(z_n)}{p(y_n, z_n|\theta, \phi)} \right)q(z_n) dz_n\\
&= \sum_{n=1}^N \int_{\Omega_Z}  \log\left(\frac{q(z_n)}{p(z_n| y_n, \theta, \phi)} \right)q(z_n) dz_n, \quad\left(\text{Baye's Rule: } \frac{p(y_n, z_n|\theta, \phi)}{p(y_n| \theta, \phi)} = p(z_n| y_n, \theta, \phi)\right)\\
&= \sum_{n=1}^N D_{\text{KL}} \left[ q(Z_n) \| p(Z_n| Y_n, \theta, \phi)\right].
\end{aligned}<p>Since $\ell(\theta, \phi)$ is a constant, the difference $\sum_{n=1}^N D_{\text{KL}} \left[ q(Z_n) \| p(Z_n| Y_n, \theta, \phi)\right] = \ell(\theta, \phi) - ELBO(\theta, \phi, q)$ descreases when $ELBO(\theta, \phi, q)$ increases (and vice versa). Thus, maximizing the ELBO is equivalent to minimizing $D_{\text{KL}} \left[ q(Z_n) \| p(Y_n| Z_n, \theta, \phi)\right]$:</p>
$$
\underset{q}{\mathrm{argmax}}\, ELBO(\theta, \phi, q) = \underset{q}{\mathrm{argmin}}\sum_{n=1}^N D_{\text{KL}} \left[ q(Z_n) \| p(Z_n| Y_n, \theta, \phi)\right].
$$<p>Thus, we see that 
\begin{aligned}
q^*(Z_n) = \underset{q}{\mathrm{argmax}}\; ELBO(\theta^*, \phi^*, q) = \underset{q}{\mathrm{argmin}}\sum_{n=1}^N D_{\text{KL}} \left[ q(Z_n) \| p(Z_n| Y_n, \theta, \phi)\right] = p(Z_n| Y_n, \theta, \phi)
\end{aligned}</p>
<p>That is, we should set the optimal distribution $q$ to be the posterior $p(Z_n| Y_n, \theta, \phi)$.</p>
<h4 id="Iteration">Iteration<a class="anchor-link" href="#Iteration">¶</a></h4><p>Of course, we know that optimizing a function with respect to each variable is not sufficient for finding the global optimum over all the variables, considered together! Thus, performing one E-step and one M-step is not enough to maximize the ELBO. We need to repeat the two steps over and over.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Question:-Why-don't-gradients-commute-with-expectation?">Question: Why don't gradients commute with expectation?<a class="anchor-link" href="#Question:-Why-don't-gradients-commute-with-expectation?">¶</a></h2><p>We have the following property of expectations:</p>
$$
\nabla_z \mathbb{E}_{x\sim p(x)}[f(x, z)] = \mathbb{E}_{x\sim p(x)}[ \nabla_z f(x, z)] 
$$<p>That is, when the gradient is with respect to a variable that does not appear in the distribution with respect to which you are taking the expectation, then you can push the gradient past the expectation.</p>
<p><strong>The intuition:</strong> the gradient with respect to $z$ is computing the changes in a function by making infinitesimally small changes to $z$, the expectation is computing the average value of a function by sampling $x$ from a distribution that does not depend on $z$. Each operation is making an independent change to two different variables and hence can be done in any order.</p>
<p>Why can't you do this in general? I.e. why is it that,</p>
$$ \nabla_z\mathbb{E}_{x\sim p(x|z)}[f(x, z)] \neq \mathbb{E}_{x\sim p(x|z)}[ \nabla_z f(x, z)]?$$<p><strong>The intuition:</strong> the gradient with respect to z is computing the changes in a function by making infinitesimally small changes to z, which in turn affects the samples produced by p(x|z), these samples finally affect the output of f. This is a chain of effects and the order matters.</p>
<p><strong>The formal proof:</strong> Consider the following case,</p>
$$
p(x\vert z) = (z+1)x^z,\; x\in [0, 1]
$$<p>and</p>
$$
f(x, z) = xzf ( x , z ) = x z.
$$<p>Then, we have</p>
$$\nabla_z \mathbb{E}_{x\sim p(x|z)} [f(x, z)] = \nabla_z \int_0^1 f(x, z) p(x|z) dx = \nabla_z\int_0^1 xz \cdot (z+1)x^z dx = \nabla_z z (z+1)\int_0^1x^{z+1} dx = \nabla_z \frac{z (z+1)}{z+2} [x^{z+2} ]_0^1 =  \nabla_z \frac{z (z+1)}{z+2} = \frac{z^2 + 4z + 2}{(z+2)^2}
$$<p>On the other hand, we have</p>
$$
\mathbb{E}_{x\sim p(x|z)}\left[ \nabla_z f(x, z) \right] = \int_0^1 \nabla_z[ xz] (z+1)x^zdx = \int_0^1(z+1)x^{z+1}dx = \frac{z+1}{z+2} [x^{z+2}]_0^1 = \frac{z+1}{z+2}.
$$<p>Note that:</p>
$$
\nabla_z \mathbb{E}_{x\sim p(x|z)} [f(x, z)] =  \frac{z^2 + 4z+ 2}{(z+2)^2} \neq \frac{z+1}{z+2} = \mathbb{E}_{x\sim p(x|z)}\left[ \nabla_z f(x, z) \right].
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Question:-Why-do-we-need-to-maximize-the-ELBO-with-respect-to-q?">Question: Why do we need to maximize the ELBO with respect to q?<a class="anchor-link" href="#Question:-Why-do-we-need-to-maximize-the-ELBO-with-respect-to-q?">¶</a></h2><p>Recall that in the derivation of the ELBO, we first introduced an auxiliary variable q to rewrite the observed log-likelihood:</p>
$$
\log p(y|\theta, \phi) = \log \int_\Omega p(y, z| \theta, \phi) dz = \log \int_\Omega \frac{p(y, z| \theta, \phi}{q(z)}q(z) dz = \log \mathbb{E}_{q(z)} \left[ \frac{p(y, z|\theta, \phi)}{q(z)} \right]
$$<p>Again, the reason why we do this is because: when we eventually take the gradient wrt to $\theta, \phi$ during optimization we can use the identity</p>
$$
\nabla_{\theta, \phi} \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right] = \mathbb{E}_{q(z)}\left[\nabla_{\theta, \phi}  \frac{p(y, z|\theta, \phi)}{q(z)}\right] 
$$<p><strong><em>At this point, there is no need to maximize over q</em></strong>, that is:</p>
$$
\max_{\theta, \phi, q}\log \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right] = \max_{\theta, \phi}\log \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right]
$$<p>The $q$ cancels and has no effect on the outcome or process of the optimization (but you can't just choose any $q$ you want - can you see what are the constraints on $q$?).</p>
<p>Now, the problem is that the log is on the outside of the expectation. This isn't a problem in the sense that we don't know how to take the derivative of a logarithm of a complex function (this is just the chain rule ),  the problem is that</p>
$$
\nabla_{\phi, \theta} \frac{p(y, z|\theta, \phi)}{q(z)}
$$<p>can be very complex (since p and q are pdf's) and so over all the gradient of the log expectation is not something you can compute roots for. Here is where we push the log inside the expectation using Jensen's inequality:</p>
$$
\log \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right]  \geq \mathbb{E}_{q(z)}\left[\log \left(\frac{p(y, z|\theta, \phi)}{q(z)}\right)\right] \overset{\text{def}}{=} ELBO(\phi, \theta, q)
$$<p>When we push the log inside the expectation, we obtain the <strong>E</strong>vidence <strong>L</strong>ower <strong>Bo</strong>und (ELBO).</p>
<p>Now, for any choice of $q$, we always have:</p>
$$
\max_{\theta, \phi}\log \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right]  \geq \max_{\theta, \phi}ELBO(\phi, \theta, q)
$$<p>But the ELBO is not necessarily a tight bound (i.e. maximizing the ELBO can be very far from maximizing the log-likelihood!)! In particular, some choices of $q$ might give you a tighter bound on the log-likelihood than others. Thus, we want to select the $q$ that give us the tightest bound:</p>
$$
\max_{\theta, \phi}\log \mathbb{E}_{q(z)}\left[\frac{p(y, z|\theta, \phi)}{q(z)}\right]  \geq \max_{\theta, \phi, q}ELBO(\phi, \theta, q).
$$
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Expectation-Maximization-Algorithm">The Expectation Maximization Algorithm<a class="anchor-link" href="#The-Expectation-Maximization-Algorithm">¶</a></h2><p>The <strong><em>exepectation maximization (EM) algorithm</em></strong> maximize the ELBO of the model,
<img src="fig/graphical_model.jpg" style="height:150px;" /></p>
<ol>
<li><strong>Initialization:</strong> Pick $\theta_0$, $\phi_0$.</li>
<li><p>Repeat $i=1, \ldots, I$ times:</p>
<p><strong>E-Step:</strong> 
$$q_{\text{new}}(Z_n) = \underset{q}{\mathrm{argmax}}\; ELBO(\theta_{\text{old}}, \phi_{\text{old}}, q) = p(Z_n|Y_n, \theta_{\text{old}}, \phi_{\text{old}})$$</p>
<p><strong>M-Step:</strong> 
\begin{aligned}
\theta_{\text{new}}, \phi_{\text{new}} &= \underset{\theta, \phi}{\mathrm{argmax}}\; ELBO(\theta, \phi, q_{\text{new}})\\
&= \underset{\theta, \phi}{\mathrm{argmax}}\; \sum_{n=1}^N\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \theta_{\text{old}}, \phi_{\text{old}})}\left[\log \left( p(y_n, Z_n | \phi, \theta\right) \right].
\end{aligned}</p>
</li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="The-Auxiliary-Function">The Auxiliary Function<a class="anchor-link" href="#The-Auxiliary-Function">¶</a></h2><p>We often denote the expectation in the M-step by $Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)$
$$
Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right) = \sum_{n=1}^N\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \theta_{\text{old}}, \phi_{\text{old}})}\left[\log \left( p(y_n, Z_n | \phi, \theta\right) \right]
$$
and call $Q$ the auxiliary function.</p>
<p>Frequently, the EM algorithm is equivalently presented as</p>
<ul>
<li>E-step: compute the auxiliary function: $Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)$</li>
<li>M-step: maximize the auxiliary function: $\theta^{\text{new}}, \phi^{\text{new}} = \underset{\theta, \phi}{\mathrm{argmax}}\,Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)$.</li>
</ul>
<p>The log of the joint distribution $\prod_{n=1}^N p(Z_n, Y_n, \theta, \phi)$ is called the <strong><em>complete data log-likelihood</em></strong> (since it is the likelihood of both observed and latent variables), whereas $\log \prod_{n=1}^N p(Y_n| \theta, \phi)$ is called the <strong><em>observed data log-likelihood</em></strong> (since it is the likelihood of only the observed variable).</p>
<p>The auxiliary function presentation of EM is easy to interpret:</p>
<ul>
<li>In the E-step, you fill in the latent variables in the complete data log-likelihood using "average" values, this leaves just an estimate of the observed log-likelihood.</li>
<li>In the M-step, you find parameters $\phi$ and $\theta$ that maximizes your estimate of the observed log-likelihood.</li>
</ul>
<p>We chose to derive EM via the ELBO in this lecture because it makes an explicit connection between the EM algorithm for estimating MLE and variational inference method for approximating the posterior of Bayesian models. It is, however, worthwhile to derive EM using the auxiliary function $Q$, as $Q$ makes it convient for us to prove properties of the EM algorithm.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Monotonicity-and-Convergence-of-EM">Monotonicity and Convergence of EM<a class="anchor-link" href="#Monotonicity-and-Convergence-of-EM">¶</a></h2><p>Before we run off estimating MLE parameters of latent variable models with EM, we need to sanity check two points:</p>
<ol>
<li><strong>(Monotonicity)</strong> we need to know that repeating the E, M-steps will never decrease the ELBO!</li>
<li><strong>(Convergence)</strong> we need to know that at some point the EM algorithm will naturally terminate (the algorithm will cease to update the parameters).</li>
</ol>
<p>We first prove the monotonicity of EM. Consider the difference between $\ell(\theta, \phi) - \ell(\theta^{\text{old}}, \phi^{\text{old}})$, i.e. the amount by which the log-likelihood can increase or decrease by going from $\theta^{\text{old}}, \phi^{\text{old}}$ to $\theta, \phi$:</p>
\begin{aligned}
\ell(\theta, \phi) - \ell(\theta^{\text{old}}, \phi^{\text{old}}) &= \sum_{n=1}^N\log \left[ \frac{p(y_n|\theta, \phi)}{p(y_n| \theta^{\text{old}}, \phi^{\text{old}})}\right]\\
&= \sum_{n=1}^N \log\int \frac{p(y_n, z_n|\theta, \phi)}{p(y_n| \theta^{\text{old}}, \phi^{\text{old}})} dz_n\\
&= \sum_{n=1}^N \log\int \frac{p(y_n, z_n|\theta, \phi)}{p(y_n| \theta^{\text{old}}, \phi^{\text{old}}) p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})}p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}}) dz_n\\
&= \sum_{n=1}^N \log\int \frac{p(y_n, z_n|\theta, \phi)}{p(y_n, z_n| \theta^{\text{old}}, \phi^{\text{old}})}p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}}) dz_n\\
&= \sum_{n=1}^N \log \mathbb{E}_{p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})} \left[\frac{p(y_n, z_n|\theta, \phi)}{p(y_n, z_n| \theta^{\text{old}}, \phi^{\text{old}})}\right]\\
&\geq \sum_{n=1}^N  \mathbb{E}_{p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})} \log\left[\frac{p(y_n, z_n|\theta, \phi)}{p(y_n, z_n| \theta^{\text{old}}, \phi^{\text{old}})}\right]\\
&= \sum_{n=1}^N  \mathbb{E}_{p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})} \left[\log  p(y_n, z_n|\theta, \phi) - \log p(y_n, z_n| \theta^{\text{old}}, \phi^{\text{old}})\right]\\
&= \sum_{n=1}^N  \mathbb{E}_{p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})} \left[\log  p(y_n, z_n|\theta, \phi)\right] - \sum_{n=1}^N  \mathbb{E}_{p(z_n|y_n, \theta^{\text{old}}, \phi^{\text{old}})}\left[ \log  p(y_n, z_n| \theta^{\text{old}}, \phi^{\text{old}})\right]\\
&= Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right) - Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right)
\end{aligned}<p>Thus, when we maximize the gain in log-likelihood going from $\theta^{\text{old}}, \phi^{\text{old}}$ to $\theta, \phi$, we get:</p>
\begin{aligned}
\underset{\theta, \phi}{\max} \left[\ell(\theta, \phi) - \ell(\theta^{\text{old}}, \phi^{\text{old}})\right] \geq \underset{\theta, \phi}{\max} \left[Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right) - Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right)\right]
\end{aligned}<p>or equivalently,</p>
\begin{aligned}
\underset{\theta, \phi}{\max} \left[\ell(\theta, \phi)\right] - \ell(\theta^{\text{old}}, \phi^{\text{old}}) \geq \underset{\theta, \phi}{\max} \left[Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)\right] - Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right).
\end{aligned}<p>Note that the above max is always greater than or equal to zero:</p>
$$\underset{\theta, \phi}{\max} \left[Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)\right] - Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right) \geq 0$$<p></p>
<p>since we can always maintain the status quo by choosing $theta = \theta^{\text{old}}$ $\phi = \phi^{\text{old}}$:</p>
$$ Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right) - Q\left(\theta^{\text{old}}, \phi^{\text{old}}| \theta^{\text{old}}, \phi^{\text{old}}\right) = 0.$$<p>Thus, we have that by maximizing $Q\left(\theta, \phi| \theta^{\text{old}}, \phi^{\text{old}}\right)$, we ensure that $\ell(\theta, \phi) - \ell(\theta^{\text{old}}, \phi^{\text{old}})\geq 0$ in each iteration of EM.</p>
<p>If the likelihood of the model is bounded above (i.e. $\ell(\theta, \phi) \leq M$ for some constant $M$), then EM is guaranteed to convergence. This is because we've proved that EM increases (or maintains) log-likelihood in each iteration, therefore, if $\ell(\theta, \phi)$ is bounded, the process must converge.</p>
<h4 id="Disclaimer:">Disclaimer:<a class="anchor-link" href="#Disclaimer:">¶</a></h4><p>Although EM converges for bounded likelihoods, it is not guaranteed to converge to the global max of the log-likelihood! Maximizing a lower bound of a function does not necessarily maximize the function itself! Often time, EM converges to local optima of the likelihood function and the point to which it converges may be very sensitive to initialization. We will study this kind of behaviour in more detail when we cover non-convex optimization later in the course.</p>
<p><img src="fig/EM.jpg" style="height:350px;" /></p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">Example: EM for the Gaussian Mixture Model of Birth Weight<a class="anchor-link" href="#Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">¶</a></h2><p>The Gaussian mixture model for the birth weight data has 3 Gaussians with meand $\mu = [\mu_1, \mu_2, \mu_3]$ and variances $\sigma^2 = [\sigma_1^2, \sigma_2^2, \sigma_3^2]$, and the model is defined as:
\begin{aligned}
Z_n &\sim Cat(\pi),\\
Y_n | Z_n &\sim \mathcal{N}(\mu_{Z_n}, \sigma^2_{Z_n}),
\end{aligned}
where $n=1, \ldots, N$ and $\sum_{k=1}^3 \pi_k = 1$.</p>
<h3 id="The-E-Step">The E-Step<a class="anchor-link" href="#The-E-Step">¶</a></h3><p>The E-step in EM computes the distribution:
$$q_{\text{new}}(Z_n) = \underset{q}{\mathrm{argmax}}\; ELBO(\mu_{i-1}, \sigma^2_{i-1}, \pi_{i_1}, q) = p(Z_n|Y_n, \mu_{\text{old}}, \sigma^2_{\text{old}}, \pi_{\text{old}}).$$ 
Since $Z_n$ is a label, $p(Z_n|Y_n, \ldots)$ is a categorical distribution, with the probability of $Z_n=k$ given by:</p>
$$
p(Z_n = k|Y_n, \mu_{\text{old}}, \sigma^2_{\text{old}}, \pi_{\text{old}}) = \frac{p(y_n|Z_n = k, \mu_{\text{old}}, \sigma^2_{\text{old}})p(Z_n=k | \pi_{\text{old}})}{\sum_{k=1}^K p(y|Z_n = k, \mu_{\text{old}}, \sigma^2_{\text{old}})p(Z_n=k | \pi_{\text{old}})} = \underbrace{\frac{\pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \sigma^2_{k, \text{old}})}{\mathcal{Z}}}_{r_{n, k}},
$$<p>where $\mathcal{Z} = \sum_{k=1}^K \pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \sigma^2_{k, \text{old}})$.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">Example: EM for the Gaussian Mixture Model of Birth Weight<a class="anchor-link" href="#Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">¶</a></h2><h3 id="Setting-Up-the-M-Step">Setting Up the M-Step<a class="anchor-link" href="#Setting-Up-the-M-Step">¶</a></h3><p>The M-step in EM maximize the following: 
$$\underset{\mu, \sigma^2, \pi}{\mathrm{argmax}}\; ELBO(\mu, \sigma^2, \pi, q_{\text{new}}) = \underset{\mu, \sigma^2, \pi}{\mathrm{argmax}}\; \sum_{n=1}^N\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \mu_{k, \text{old}}, \sigma^2_{k, \text{old}})}\left[\log \left( p(y_n, Z_n | \mu, \sigma^2, \pi\right) \right].$$</p>
<p>If we expand the expectation a little, we get:
\begin{aligned}
\sum_{n=1}^N\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \mu_{\text{old}}, \sigma^2_{\text{old}}, \pi_{\text{old}})}\left[\log \left(p(y_n, Z_n | \mu, \sigma^2, \pi) \right) \right] &= \sum_{n=1}^N \underbrace{\sum_{n=1}^K \log \left(\underbrace{ p(y_n| Z_n=k, \mu, \sigma^2) p(Z_n=k| \pi)}_{\text{factoring the joint }p(y_n, Z_n| \ldots) } \right) p(Z_n=k|y_n, \theta_{\text{old}}, \phi_{\text{old}})}_{\text{expanding the expectation}}\\
&=\sum_{n=1}^N \sum_{k=1}^K \underbrace{r_{n, k}}_{p(Z_n=k|y_n, \theta_{\text{old}}, \phi_{\text{old}})} \left[\log \underbrace{\mathcal{N}(y_n; \mu_k, \sigma^2_k)}_{p(y_n| Z_n=k, \mu, \sigma^2)}  + \log \underbrace{\pi_k}_{p(Z_n=k| \pi)}\right]\\
&= \underbrace{\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \mathcal{N}(y_n; \mu_k, \sigma^2_k)}_{\text{Term #1}} + \underbrace{\sum_{n=1}^N \sum_{k=1}^K r_{n, k}\pi_k}_{\text{Term #2}} 
\end{aligned}
We can maximize each Term #1 and Term #2 individually.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">Example: EM for the Gaussian Mixture Model of Birth Weight<a class="anchor-link" href="#Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">¶</a></h2><h3 id="Solving-the-M-Step">Solving the M-Step<a class="anchor-link" href="#Solving-the-M-Step">¶</a></h3><p>We see that the optimization problem in the M-step: $\mu_{\text{new}}, \sigma^2_{\text{new}}, \pi_{\text{new}} = \underset{\mu, \sigma^2, \pi}{\mathrm{argmax}}\; ELBO(\mu, \sigma^2, \pi, q_{\text{new}})$ is equivalent to two problems
\begin{aligned}
&1.\quad \underset{\mu, \sigma^2}{\mathrm{argmax}}\; \sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \mathcal{N}(y_n; \mu_k, \sigma^2_k)\\
&2.\quad \underset{\pi}{\mathrm{argmax}}\; \sum_{n=1}^N \sum_{k=1}^K r_{n, k}\pi_k
\end{aligned}
We can solve each optimization problem analytically by finding stationary points of the gradient (or the Lagrangian):</p>
<ul>
<li><p>$\mu_{\text{new}} = \frac{1}{ \sum_{n=1}^N r_{n, k}} \sum_{n=1}^N r_{n, k} y_n$</p>
</li>
<li><p>$\sigma^2_{\text{new}} = \frac{1}{ \sum_{n=1}^N r_{n, k}} \sum_{n=1}^N r_{n, k} (y_n - \mu_{\text{new}})^2$</p>
</li>
<li><p>$\pi_{\text{new}} =  \frac{\sum_{n=1}^N r_{n, k}}{N}$</p>
</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">Example: EM for the Gaussian Mixture Model of Birth Weight<a class="anchor-link" href="#Example:-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">¶</a></h2><h3 id="All-Together">All Together<a class="anchor-link" href="#All-Together">¶</a></h3><p><strong>Initialization:</strong>
Pick any $\pi$, $\mu$, $\sigma^2$</p>
<p><strong>E-Step:</strong>
Compute $r_{n, k} = \displaystyle\frac{\pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \sigma^2_{k, \text{old}})}{\mathcal{Z}}$, where $\mathcal{Z} = \sum_{k=1}^K \pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \sigma^2_{k, \text{old}})$.</p>
<p><strong>M-Step:</strong>
Compute model parameters:</p>
<ul>
<li><p>$\mu_{\text{new}} = \frac{1}{ \sum_{n=1}^N r_{n, k}} \sum_{n=1}^N r_{n, k} y_n$</p>
</li>
<li><p>$\sigma^2_{\text{new}} = \frac{1}{ \sum_{n=1}^N r_{n, k}} \sum_{n=1}^N r_{n, k} (y_n - \mu_{\text{new}})^2$</p>
</li>
<li><p>$\pi_{\text{new}} =  \frac{\sum_{n=1}^N r_{n, k}}{N}$</p>
</li>
</ul>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implementing-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">Implementing EM for the Gaussian Mixture Model of Birth Weight<a class="anchor-link" href="#Implementing-EM-for-the-Gaussian-Mixture-Model-of-Birth-Weight">¶</a></h2>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [2]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="c1">#Generate data</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">2000</span>
<span class="n">pis</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="n">mus</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mf">7.8</span><span class="p">]</span>
<span class="n">sigmas</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.5</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.7</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">**</span><span class="mi">2</span><span class="p">]</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">zs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">K</span><span class="p">),</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">pis</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">mus</span><span class="p">[</span><span class="n">z</span><span class="p">],</span> <span class="n">sigmas</span><span class="p">[</span><span class="n">z</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="n">zs</span><span class="p">])</span>

<span class="c1">#initialization</span>
<span class="n">mu_init</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">]</span>
<span class="n">sigma_init</span> <span class="o">=</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]</span>
<span class="n">pi_init</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">]</span>

<span class="c1">#implement EM</span>
<span class="n">mu_current</span> <span class="o">=</span> <span class="n">mu_init</span>
<span class="n">sigma_current</span> <span class="o">=</span> <span class="n">sigma_init</span>
<span class="n">pi_current</span> <span class="o">=</span> <span class="n">pi_init</span>

<span class="n">log_lkhd</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">total_iter</span> <span class="o">=</span> <span class="mi">1500</span>
<span class="n">threshold</span> <span class="o">=</span> <span class="mf">1e-10</span>

<span class="n">mu_diff</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">pi_diff</span> <span class="o">=</span> <span class="mf">1.</span>
<span class="n">sigma_diff</span> <span class="o">=</span> <span class="mf">1.</span>

<span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>

<span class="k">while</span> <span class="n">i</span> <span class="o"><</span> <span class="n">total_iter</span> <span class="ow">and</span> <span class="n">mu_diff</span> <span class="o">></span> <span class="n">threshold</span> <span class="ow">and</span> <span class="n">pi_diff</span> <span class="o">></span> <span class="n">threshold</span> <span class="ow">and</span> <span class="n">sigma_diff</span> <span class="o">></span> <span class="n">threshold</span><span class="p">:</span>
    <span class="c1">#E-step</span>
    <span class="n">r_unnormalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([(</span><span class="n">pi_current</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">*</span>  <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_current</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">sigma_current</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)])</span><span class="o">.</span><span class="n">T</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">r_unnormalized</span> <span class="o">/</span> <span class="n">r_unnormalized</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1">#M-step</span>
    <span class="n">mu_next</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">r</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">r</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)])</span>
    <span class="n">sigma_next</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">1.</span> <span class="o">/</span> <span class="n">r</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="n">r</span><span class="p">[:,</span> <span class="n">k</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">mu_next</span><span class="p">[</span><span class="n">k</span><span class="p">])</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)])</span>
    <span class="n">pi_next</span> <span class="o">=</span> <span class="n">r</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">/</span> <span class="n">r</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    
    <span class="c1">#compute log observed likelihood</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'iteration '</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">ll</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)):</span>
            <span class="n">ll</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">([</span><span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_next</span><span class="p">[</span><span class="n">k</span><span class="p">],</span> <span class="n">sigma_next</span><span class="p">[</span><span class="n">k</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">n</span><span class="p">])</span> <span class="o">*</span> <span class="n">pi_next</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">K</span><span class="p">)]))</span> 
        <span class="n">log_lkhd</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">ll</span><span class="p">)</span>
        
    <span class="c1">#convergence check</span>
    <span class="n">mu_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_next</span> <span class="o">-</span> <span class="n">mu_current</span><span class="p">)</span>
    <span class="n">pi_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">pi_next</span> <span class="o">-</span> <span class="n">pi_current</span><span class="p">)</span>
    <span class="n">sigma_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">sigma_next</span> <span class="o">-</span> <span class="n">sigma_current</span><span class="p">)</span>
           
    <span class="c1">#update parameters</span>
    <span class="n">mu_current</span> <span class="o">=</span> <span class="n">mu_next</span>
    <span class="n">sigma_current</span> <span class="o">=</span> <span class="n">sigma_next</span>
    <span class="n">pi_current</span> <span class="o">=</span> <span class="n">pi_next</span>
    <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">max</span><span class="p">(),</span> <span class="mi">100</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_subarea output_stream output_stdout output_text">
<pre>iteration  0
iteration  100
iteration  200
iteration  300
iteration  400
iteration  500
iteration  600
iteration  700
iteration  800
iteration  900
iteration  1000
iteration  1100
iteration  1200
iteration  1300
iteration  1400
</pre>
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [3]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">60</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'gray'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'histogram of birth weights'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pi_current</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_current</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">sigma_current</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'First Gaussian'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pi_current</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_current</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">sigma_current</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">'blue'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Second Gaussian'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pi_current</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="n">sp</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">mu_current</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">sigma_current</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">**</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="s1">'green'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">'Third Gaussian'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'GMM for Birth Weights'</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">'best'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_png output_subarea">
<img src="data:image/png;base64,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
" />
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Example:-EM-for-Gaussian-Mixture-Models-(Multivariate)">Example: EM for Gaussian Mixture Models (Multivariate)<a class="anchor-link" href="#Example:-EM-for-Gaussian-Mixture-Models-(Multivariate)">¶</a></h2><p>Recall that our Gaussian mixture model, of $K$ number of Gaussians with means $\mu = [\mu_1, \ldots, \mu_K]$ and covariances $\Sigma = [\Sigma_1, \ldots, \Sigma_K]$, is defined as:</p>
\begin{aligned}
Z_n &\sim Cat(\pi),\\
Y_n &\sim \mathcal{N}(\mu_{Z_n}, \Sigma_{Z_n}),
\end{aligned}<p>where $n=1, \ldots, N$ and $\sum_{k=1}^K \pi_k = 1$.</p>
<p>We derive the updates for $\pi$, $\mu$ and $\Sigma$ for the EM algorithm</p>
<h4 id="E-step:">E-step:<a class="anchor-link" href="#E-step:">¶</a></h4>$$
q_{\text{new}} = p(Z_n|y_n, \pi_{\text{old}}, \mu_{\text{old}}, \Sigma_{\text{old}}) = \frac{p(y_n|Z_n, \mu_{\text{old}}, \Sigma_{\text{old}})p(Z_n|\pi_{\text{old}})}{\int p(y_n|z_n, \mu_{\text{old}}, \Sigma_{\text{old}})p(z_n|\pi_{\text{old}}) dz_n}
$$<p>Since $Z_n$ is a categorical variable, we compute the probability of $Z_n = k$ separately:</p>
$$
p(Z_n = k|y_n, \pi_{\text{old}}, \mu_{\text{old}}, \Sigma_{\text{old}}) = \frac{p(y_n|Z_n = k, \mu_{\text{old}}, \Sigma_{\text{old}})p(Z_n=k | \pi_{\text{old}})}{\sum_{k=1}^K p(y|Z_n = k, \mu_{\text{old}}, \Sigma_{\text{old}})p(Z_n=k | \pi_{\text{old}})} = \underbrace{\frac{\pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \Sigma_{k, \text{old}})}{\mathcal{Z}}}_{r_{n, k}}
$$<p>where $\mathcal{Z} = \sum_{k=1}^K \pi_{k, \text{old}}\,\mathcal{N}(y_n; \mu_{k, \text{old}}, \Sigma_{k, \text{old}})$.</p>
<p>Thus, $q_{\text{new}}(Z_n)$ is a categorical distribution $Cat([r_{n, 1}, \ldots, r_{n, K}])$.</p>
<h4 id="M-Step:">M-Step:<a class="anchor-link" href="#M-Step:">¶</a></h4>\begin{aligned}
\mu_{\text{new}}, \Sigma_{\text{new}}, \pi_{\text{new}} &= \underset{\mu, \Sigma, \pi}{\mathrm{argmax}}\, \sum_{n=1}^N\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \mu_{\text{old}}, \Sigma_{\text{old}}, \pi_{\text{old}})}\left[\log \left( p(y_n, Z_n | \mu, \sigma \right) \right]\\
&= \underset{\mu, \Sigma, \pi}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \left[\log p(y_n | Z_n=k, \mu, \Sigma)  + \log p(Z_n=k | \pi)\right]\\
&= \underset{\mu, \Sigma}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log p(y_n | Z_n=k, \mu, \Sigma)  + \underset{\pi}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log p(Z_n=k | \pi)\\
&=\underset{\mu, \Sigma}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \mathcal{N}(y_n; \mu_{k}, \Sigma_{k})  + \underset{\pi}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \pi_k
\end{aligned}<p>where $n=1, \ldots, N$ and $\sum_{k=1}^K \pi_k = 1$.</p>
<p>We solve the two optimization problems separately. The optimization problem</p>
$$
\underset{\pi}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \pi_k,\quad \sum_{k=1}^K \pi_k = 1
$$<p>can be solved using Lagrangian multipliers yielding the solution:</p>
$$
\pi_{\text{new}, k} = \frac{\sum_{n=1}^N r_{n, k}}{N}
$$<p>The optimization problem</p>
$$
\underset{\mu, \Sigma}{\mathrm{argmax}}\,\sum_{n=1}^N \sum_{k=1}^K r_{n, k} \log \mathcal{N}(y_n; \mu_{k}, \Sigma_{k}) 
$$<p>can be solved by taking the gradient with respect to $\mu_k$, $\Sigma_k$ for each $k$ and computing the stationary points of the gradient (remember to check for the global concavity to ensure you've found a global max). Doing so gives us the optimal points</p>
\begin{aligned}
\mu_{\text{new},k} &= \frac{1}{\sum_{n=1}^N r_{n, k}} \sum_{n=1}^N r_{n,k}y_n, &\quad (\text{weighted sample mean})\\
\Sigma_{\text{new},k} &= \frac{1}{\sum_{n=1}^N r_{n, k}}  \sum_{n=1}^N r_{n,k} (y_n - \mu_{\text{new},k})(y_n - \mu_{\text{new},k})^\top, &\quad (\text{weighted sample covariance})
\end{aligned}<p><strong>Exercise:</strong> Verify that the updates for $\pi_{\text{new},k}, \mu_{\text{new},k}, \Sigma_{\text{new},k}$ maximizes $\mathbb{E}_{Z_n\sim p(Z_n|Y_n, \mu_{\text{old}}, \Sigma_{\text{old}}, \pi_{\text{old}})}\left[\log \left( p(y_n, Z_n | \mu, \sigma \right) \right]$.</p>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Sanity-Check:-Log-Likelihood-During-Training">Sanity Check: Log-Likelihood During Training<a class="anchor-link" href="#Sanity-Check:-Log-Likelihood-During-Training">¶</a></h2><p>Remember that ploting the MLE model against actual data is not always an option (e.g. high-dimensional data).</p>
<p>A sanity check for that your EM algorithm has been implemented correctly is to plot the observed data log-likelihood over the iterations of the algorithm:
$$
\ell_y(\mu, \sigma^2, \pi) = \sum_{n=1}^N \log \sum_{k=1}^K \mathcal{N}(y_n; \mu_k, \sigma_k^2) \pi_k
$$</p>
</div>
</div>
</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In [4]:</div>
<div class="inner_cell">
<div class="input_area">
<div class="highlight hl-ipython3"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">log_lkhd</span><span class="p">)),</span> <span class="n">log_lkhd</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s1">'observed data log-likelihood over iterations of EM'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="output_wrapper">
<div class="output">
<div class="output_area">
<div class="prompt"></div>
<div class="output_png output_subarea">
<img src="data:image/png;base64,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
" />
</div>
</div>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Expectation-Maximization-versus-Gradient-based-Optimization">Expectation Maximization versus Gradient-based Optimization<a class="anchor-link" href="#Expectation-Maximization-versus-Gradient-based-Optimization">¶</a></h2><p><strong>Pros of EM:</strong></p>
<ol>
<li>No learning rates to adjust</li>
<li>Don't need to worry about incorporating constraints (i.e. $p(Z_n|Y_n)$ is between 0 and 1)</li>
<li>Each iteration is guaranteed to increase or maintain observed data log-likelihood</li>
<li>Is guaranteed to converge to local optimum</li>
<li>Can be very fast to converge (when parameters are fewer)</li>
</ol>
<p><strong>Cons of EM:</strong></p>
<ol>
<li>Can get stuck in local optima</li>
<li>May not maximize observed data log-likelihood (the ELBO is just a lower bound)</li>
<li>Requires you to do math - you need analytic solutions for E-step and M-step</li>
<li>May be much slower than fancier gradient-based optimization</li>
</ol>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h1 id="Review-of-EM-for-Latent-Variable-Models">Review of EM for Latent Variable Models<a class="anchor-link" href="#Review-of-EM-for-Latent-Variable-Models">¶</a></h1>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="prompt input_prompt">
</div><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Review:-Latent-Variable-Models">Review: Latent Variable Models<a class="anchor-link" href="#Review:-Latent-Variable-Models">¶</a></h2><p>Models that include an observed variable $Y$ and at least one unobserved variable $Z$ are called <strong><em>latent variable models</em></strong>. In general, our model can allow $Y$ and $Z$ to interact in many different ways. We have studied models with one type of interaction:</p>
<p><img src="fig/graphical_model.jpg" style="height:200px;" /></p>
<p>We treat the parameters $\theta$ and $\phi$ as <em>unknown constants</em>, and we estimate them from the observed data $y_1, \ldots, y_N$.</p>
<h3 id="Example:-Gaussian-Mixture-Models-(GMMs)">Example: Gaussian Mixture Models (GMMs)<a class="anchor-link" href="#Example:-Gaussian-Mixture-Models-(GMMs)">¶</a></h3><p>In a <strong><em>Gaussian Mixture Model (GMM)</em></strong>, we posit that the observed data $Y$ is generated by a mixture, $\pi=[\pi_1, \ldots, \pi_K]$, of $K$ number of Gaussians with means $\mu = [\mu_1, \ldots, \mu_K]$ and covariances $\Sigma = [\Sigma_1, \ldots, \Sigma_K]$. For each observation $Y_n$ the class of the observation $Z_n$ is a latent variable that indicates which of the $K$ Gaussian is responsible for generating $Y_n$:</p>
\begin{aligned}
Z_n &\sim Cat(\pi),\\
Y_n | Z_n&\sim \mathcal{N}(\mu_{Z_n}, \Sigma_{Z_n}),
\end{aligned}<p>where $n=1, \ldots, N$ and $\sum_{k=1}^K \pi_k = 1$.</p>
<p>GMMs are examples of <strong><em>model based clustering</em></strong> - breaking up a data set into natural clusters based on a statistical model fitted to the data.</p>
<p>Inference for this model may mean that we want to learn the mean and covariance for each class in the mixture. Or we may want to infer the class membership $z_n$ for each observation $y_n$.</p>
<h3 id="Maximum-Likelihood-Estimate-Inference-for-Latent-Variable-Models">Maximum Likelihood Estimate Inference for Latent Variable Models<a class="anchor-link" href="#Maximum-Likelihood-Estimate-Inference-for-Latent-Variable-Models">¶</a></h3><p>If we are interested in computing the maximum likelihood estimators of the parameters $\theta$ and $\phi$, we need to compute them with respect to the <strong><em>observed likelihood</em></strong> $p(y| \theta, \phi)$ - this is simply because we don't have access to the latent variable values, so we can't evaluate $p(y, z| \theta, \phi)$ given values for $\theta$ and $\phi$.</p>
<p>Just like from before, we maximize the log-likelihood rather than the likelihood due to the simplifying properties of the log function:</p>
$$
\theta^*, \phi^* = \underset{\theta, \phi}{\text{argmax}}\; \ell_y(\theta, \phi) = \underset{\theta, \phi}{\text{argmax}}\; \log p(y| \theta, \phi) = \underset{\theta, \phi}{\text{argmax}}\;\log \int p(y, z| \theta, \phi)\, dz
$$<p>Maximizing the the above requires taking a gradient,</p>
$$
\nabla_{\theta, \phi} \log \int p(y, z| \theta, \phi)\, dz
$$<p>but it's not clear how to evaluate this expression. Rewriting the integral as an expectation, it turns out, illuminates the source of the problem:</p>
$$
\nabla_{\theta, \phi} \log \int p(y, z| \theta, \phi)\, dz = \nabla_{\theta, \phi} \log \int p(y| z,  \phi)p(z|\theta)\, dz = \nabla_{\theta, \phi} \log \mathbb{E}_{z\sim p(z|\theta)}[p(y| z,  \phi)] = \frac{\nabla_{\theta, \phi} \mathbb{E}_{z\sim p(z|\theta)}[p(y| z,  \phi)]}{\mathbb{E}_{z\sim p(z|\theta)}[p(y| z,  \phi)]},\quad \text{(chain rule)}
$$<p>The above makes it clear that the gradient is not trivial to compute -- the gradient cannot be pushed into the expectation, since the distribution with respect to which we are taking the expectation depends on the optimization variable $\theta$.</p>
<p>To make the gradient computation easier, we make two changes:</p>
<ol>
<li><p>we introduce an auxiliary variable $q(z)$ so that we can replace $\mathbb{E}_{z\sim p(z|\theta)}$ with $\mathbb{E}_{z\sim q(z)}$. Note then the latter expectation no longer depends on $\theta$.</p>
</li>
<li><p>we push the log inside the expectation using Jensen's inequality.</p>
</li>
</ol>
<p>That is, 
\begin{aligned}
\ell_y(\theta, \phi) &= \log \int p(y, z| \theta, \phi)\, dz\\
&= \log \int \frac{p(y, z| \theta, \phi)}{q(z)}q(z)\, dz\\
&= \log \mathbb{E}_{z\sim q(z)}\left[\frac{p(y, z| \theta, \phi)}{q(z)}\right]\\
&\geq \underbrace{\mathbb{E}_{z\sim q(z)} \left[\log\left(\frac{p(y, z| \theta, \phi)}{q(z)}\right)\right]}_{ELBO(\theta, \phi, q)}
\end{aligned}</p>
<p>We have dervied that $ELBO(\theta, \phi, q)$ is a lower bound of the log-likelihood $\ell_y(\theta, \phi)$, for any choice of $q$. So rather than maximizing the log-likelihood, we maximize the $ELBO(\theta, \phi, q)$, thus ensuring that $\ell_y(\theta, \phi)$ is at least as big:</p>
$$
\underset{\theta, \phi}{\max}\ell_y(\theta, \phi)\geq \underset{\theta, \phi, q}{\max}ELBO(\theta, \phi, q)
$$<p>In order to maximize the ELBO, we use coordinate ascent. That is, we take turns maximizing the ELBO with respect to $q$ and then with repect to $\theta, \phi$.</p>
<p>This algorithm is called <strong><em>expectation maximization (EM)</em></strong>.</p>
</div>
</div>
</div>

<script type="text/javascript">if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
    mathjaxscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: 'center'," +
        "    displayIndent: '0em'," +
        "    showMathMenu: true," +
        "    tex2jax: { " +
        "        inlineMath: [ ['$','$'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        " linebreaks: { automatic: true, width: '95% container' }, " +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
        "    } " +
        "}); ";
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
</script>
     </main>

<footer class="footer">
  <div class="container">
    <span class="text-muted">Copyright 2022 &copy;
      <a class="text-muted" href="https://iacs.seas.harvard.edu/">Institute for Applied Computational Science</a>
    </span>
  </div>
</footer>     <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
    <script
      src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.3/umd/popper.min.js"
      integrity="sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49"
      crossorigin="anonymous"
    ></script>
    <script
      src="https://stackpath.bootstrapcdn.com/bootstrap/4.1.1/js/bootstrap.min.js"
      integrity="sha384-smHYKdLADwkXOn1EmN1qk/HfnUcbVRZyYmZ4qpPea6sjB/pTJ0euyQp0Mk8ck+5T"
      crossorigin="anonymous"
    ></script>
  </body>
</html>