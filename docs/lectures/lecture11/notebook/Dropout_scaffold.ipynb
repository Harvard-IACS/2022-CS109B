{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title :\n",
    "Dropout\n",
    "\n",
    "## Description :\n",
    "\n",
    "The goal of this exercise is to understand and use **dropouts for neural network regularization.\n",
    "\n",
    "This method avoids overfitting by briefly switching off certain weights during training.\n",
    "\n",
    "NOTE: This graph is only a sample.\n",
    "\n",
    "<img src=\"../fig/fig4.png\" style=\"width: 500px;\">\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "- Use the helper function `unregularized_model` to:\n",
    "    - Generate the predictor and response data using the helper code given.\n",
    "    - Build a simple neural network with 5 hidden layers with 100 neurons each and display the trace plot. This network has no regularization.\n",
    "- For the same model architecture implement dropout by adding appropriate dropout layers.\n",
    "- Compile the model with MSE as the loss. Fit the model on the training data.\n",
    "- Use the helper code to visualise the MSE of the train and test data with respect to the epochs.\n",
    "- Predict on the entire data. \n",
    "- Use the helper code to plot the predictions along with the generated data.\n",
    "- This plot will consist of the predictions of both the neural networks. The graph will look similar to the one given above.\n",
    "\n",
    "## Hints: \n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\" target=\"_blank\">tf.keras.sequential()</a>\n",
    "A sequential model is for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/optimizers\" target=\"_blank\">tf.keras.optimizers()</a>\n",
    "An optimizer is one of the two arguments required for compiling a Keras model\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\" target=\"_blank\">model.add()</a>\n",
    "Adds layers to the model.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile\" target=\"_blank\">model.compile()</a>\n",
    "Compiles the layers defined into a neural network\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model\" target=\"_blank\">model.fit()</a>\n",
    "Fits the data to the neural network\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/Model\" target=\"_blank\">model.predict()</a>\n",
    "Used to predict the values given the model\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History\" target=\"_blank\">history()</a>\n",
    "The history object is returned from calls to the fit() function used to train the model. Metrics are stored in a dictionary in the history member of the object returned.\n",
    "\n",
    "<a href=\"https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dropout\" target=\"_blank\">tf.keras.layers.Dropout()</a>\n",
    "Applies Dropout to the input data of the layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "np.random.seed(0)\n",
    "tf.random.set_seed(0)\n",
    "from helper import unregularized_model\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement an unregularized NN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the helper function unregularized_model() to get the \n",
    "# unregularized model along with the data\n",
    "x_b, x_train, x_test, y_train, y_test, y_pred, mse = unregularized_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the MSE of the unregularized model\n",
    "print(\"MSE of the unregularized model is\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement the NN with dropouts\n",
    "For dropout we build the same network with \"Dropout\" layers after each activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = models.Sequential(name='Dropout_regularized')\n",
    "\n",
    "# Hidden 5 layer with 100 neurons each (or nodes)\n",
    "# Add a dropout layer after each hidden layer with some dropout percentage\n",
    "model_2.add(layers.Dense(100, activation='relu', input_shape=(1,)))\n",
    "model_2.add(___)\n",
    "\n",
    "model_2.add(layers.Dense(100, activation='relu'))\n",
    "model_2.add(___)\n",
    "\n",
    "model_2.add(layers.Dense(100, activation='relu'))\n",
    "model_2.add(___)\n",
    "\n",
    "model_2.add(layers.Dense(100, activation='relu'))\n",
    "model_2.add(___)\n",
    "\n",
    "model_2.add(layers.Dense(100, activation='relu'))\n",
    "model_2.add(___)\n",
    "\n",
    "# Output layer with one neuron \n",
    "model_2.add(layers.Dense(1,  activation='linear'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with MSE as loss and Adam optimizer with learning rate as 0.001\n",
    "___\n",
    "\n",
    "# Save the history about the model after fitting on the train data\n",
    "# Use 0.2 validation split  with 1500 epochs and batch size of 10\n",
    "history_2 = ___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper code to plot the data\n",
    "\n",
    "# Plot the MSE of the model\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.title(\"Dropout Regularized\")\n",
    "plt.semilogy(history_2.history['loss'], label='Train Loss', color='#FF9A98', linewidth=2)\n",
    "plt.semilogy(history_2.history['val_loss'],  label='Validation Loss', color='#75B594', linewidth=2)\n",
    "plt.legend()\n",
    "\n",
    "# Set the axes labels\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ In the trace plot above, why is the validation error lower than the training error?\n",
    "\n",
    "\n",
    "#### A. The dropout percentage is high and hence the model is underfit during validation.\n",
    "#### B. During the validation phase, the validation loss is multiplied by the percentage of dropout, hence the loss is always lower than the training loss.\n",
    "#### C. The dropout percentage is low and hence the model overfits on the validation data.\n",
    "#### D. The validation takes place in the evaluation mode of dropout where the weights are already learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow1) ###\n",
    "# Submit an answer choice as a string below \n",
    "# (eg. if you choose option A, put 'A')\n",
    "answer1 = '___'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_mse) ###\n",
    "# Predict your model on x_b (used exclusively for plotting)\n",
    "y_hat_dropout = ___\n",
    "\n",
    "# Predict your model on the test data \n",
    "y_dropout_test = ___\n",
    "\n",
    "# Compute the MSE on the test data\n",
    "mse_dropout = ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the MSE of the dropout regularized model\n",
    "print(\"MSE of the dropout regularized model is\", mse_dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the helper code to plot the predicted data\n",
    "\n",
    "# Plotting the predicted data using the L2 regularized model\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "plt.plot(x_b, y_hat_dropout, label='Dropout regularized', color='black', linewidth=2)\n",
    "\n",
    "# Plotting the predicted data using the unregularized model\n",
    "plt.plot(x_b, y_pred, label = 'Unregularized model', color='#005493', linewidth=2)\n",
    "\n",
    "# Plotting the training data\n",
    "plt.plot(x_train, y_train, '.', label='Train data', markersize=15, color='#FF9A98')\n",
    "\n",
    "# Plotting the testing data\n",
    "plt.plot(x_test,y_test, '.', label='Test data', markersize=15, color='#75B594')\n",
    "\n",
    "# Set the axes labels\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ⏸ **After marking the exercise, change dropout percentage to 0.8 first and 0.2 next. Do you notice any change? Which value regularizes the neural network more?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "### edTest(test_chow2) ###\n",
    "# Type your answer within in the quotes given\n",
    "\n",
    "answer2 = '___'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
